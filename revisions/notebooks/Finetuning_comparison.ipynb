{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef23a78",
   "metadata": {},
   "source": [
    "# Notebook for exploring the heatmap results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29930456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610265c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../../'\n",
    "paths = {\n",
    "# standard resutls (internal, external)\n",
    "'p1':'results/evaluation_test/plots/',\n",
    "# model pooling / ensembling:\n",
    "'p2': 'results/evaluation_test/prediction_pooled_subsampled/max/plots/',\n",
    "# finetuned models on 10%:\n",
    "'p3': 'results/finetuning/evaluation_test/plots/',\n",
    "# baseline (of finetuning) on 10%:\n",
    "'p4': 'results/finetuning/evaluation_test/baseline/plots/',\n",
    "# finetuned models on 10%:\n",
    "'p5': 'results/finetuning_0_20/evaluation_test/plots/',\n",
    "# baseline (of finetuning) on 10%:\n",
    "'p6': 'results/finetuning_0_20/evaluation_test/baseline/plots/',\n",
    "# finetuning 10% + pooled preds\n",
    "'p7': 'results/finetuning/evaluation_test/prediction_pooled_subsampled/max/plots',\n",
    "}\n",
    "paths = {key: os.path.join(base_dir, val) for key, val in paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ba4d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p1': '../../results/evaluation_test/plots/',\n",
       " 'p2': '../../results/evaluation_test/prediction_pooled_subsampled/max/plots/',\n",
       " 'p3': '../../results/finetuning/evaluation_test/plots/',\n",
       " 'p4': '../../results/finetuning/evaluation_test/baseline/plots/',\n",
       " 'p5': '../../results/finetuning_0_20/evaluation_test/plots/',\n",
       " 'p6': '../../results/finetuning_0_20/evaluation_test/baseline/plots/',\n",
       " 'p7': '../../results/finetuning/evaluation_test/prediction_pooled_subsampled/max/plots'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e4d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_paths = {key: os.path.join(path, 'roc_summary_subsampled.csv') for key, path in paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f80a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_paths = {key: os.path.join(path, 'scatter_agg_data.csv') for key, path in paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec992953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/finetuning_0_20/evaluation_test/plots/scatter_agg_data.csv\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatter_raw_data.csv\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_aumc_eicu_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_aumc_hirid_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_aumc_mimic_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_eicu_aumc_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_eicu_hirid_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_eicu_mimic_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_hirid_aumc_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_hirid_eicu_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_hirid_mimic_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_mimic_aumc_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_mimic_eicu_pat_thres_80_subsampled.png\r\n",
      "../../results/finetuning_0_20/evaluation_test/plots/scatterplot_mimic_hirid_pat_thres_80_subsampled.png\r\n"
     ]
    }
   ],
   "source": [
    "ls ../../results/finetuning_0_20/evaluation_test/plots/scatter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1cc993a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p1': '../../results/evaluation_test/plots/',\n",
       " 'p2': '../../results/evaluation_test/prediction_pooled_subsampled/max/plots/',\n",
       " 'p3': '../../results/finetuning/evaluation_test/plots/',\n",
       " 'p4': '../../results/finetuning/evaluation_test/baseline/plots/',\n",
       " 'p5': '../../results/finetuning_0_20/evaluation_test/plots/',\n",
       " 'p6': '../../results/finetuning_0_20/evaluation_test/baseline/plots/',\n",
       " 'p7': '../../results/finetuning/evaluation_test/prediction_pooled_subsampled/max/plots'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "364fe85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key: pd.read_csv(val) for key,val in roc_paths.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9419aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key: df.drop(columns='Unnamed: 0') for key, df in dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0be8b62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.columns for k, df in dfs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcc436a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['p3']['finetuned'] = True\n",
    "dfs['p1']['finetuned'] = False\n",
    "dfs['p2']['finetuned'] = False\n",
    "dfs['p4']['finetuned'] = False\n",
    "dfs['p5']['finetuned'] = True\n",
    "dfs['p6']['finetuned'] = False\n",
    "dfs['p7']['finetuned'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6f5e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator if it's the finetuning baseline:\n",
    "dfs['p3']['baseline'] = False\n",
    "dfs['p1']['baseline'] = False\n",
    "dfs['p2']['baseline'] = False\n",
    "dfs['p4']['baseline'] = True\n",
    "dfs['p5']['baseline'] = False\n",
    "dfs['p6']['baseline'] = True\n",
    "dfs['p7']['baseline'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51186bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning size: (training size for baseline)\n",
    "dfs['p3']['finetuning_size'] = 0.10\n",
    "dfs['p1']['finetuning_size'] = np.nan\n",
    "dfs['p2']['finetuning_size'] = np.nan\n",
    "dfs['p4']['finetuning_size'] = 0.10\n",
    "dfs['p5']['finetuning_size'] = 0.02\n",
    "dfs['p6']['finetuning_size'] = 0.02\n",
    "dfs['p7']['finetuning_size'] = 0.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f2e6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning size: (training size for baseline)\n",
    "dfs['p3']['pooled'] = False\n",
    "dfs['p1']['pooled'] = False\n",
    "dfs['p2']['pooled'] = True\n",
    "dfs['p4']['pooled'] = False\n",
    "dfs['p5']['pooled'] = False\n",
    "dfs['p6']['pooled'] = False\n",
    "dfs['p7']['pooled'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8edc4344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRUModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>0.014407</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.893829</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.883245</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mews</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.718061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>mews</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.609294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>news</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.652844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>qsofa</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.565961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>sirs</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.609423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>sofa</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.693076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              model train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       "0    AttentionModel          aumc         aumc  0.917711  0.003569      False   \n",
       "1          GRUModel          aumc         aumc  0.856986  0.014407      False   \n",
       "2              lgbm          aumc         aumc  0.893829  0.004515      False   \n",
       "3                lr          aumc         aumc  0.883245  0.001715      False   \n",
       "4              mews          aumc         aumc  0.718061  0.000000      False   \n",
       "..              ...           ...          ...       ...       ...        ...   \n",
       "175            mews         mimic        mimic  0.609294  0.000000      False   \n",
       "176            news         mimic        mimic  0.652844  0.000000      False   \n",
       "177           qsofa         mimic        mimic  0.565961  0.000000      False   \n",
       "178            sirs         mimic        mimic  0.609423  0.000000      False   \n",
       "179            sofa         mimic        mimic  0.693076  0.000000      False   \n",
       "\n",
       "     baseline  finetuning_size  pooled  \n",
       "0       False              NaN   False  \n",
       "1       False              NaN   False  \n",
       "2       False              NaN   False  \n",
       "3       False              NaN   False  \n",
       "4       False              NaN   False  \n",
       "..        ...              ...     ...  \n",
       "175     False              NaN   False  \n",
       "176     False              NaN   False  \n",
       "177     False              NaN   False  \n",
       "178     False              NaN   False  \n",
       "179     False              NaN   False  \n",
       "\n",
       "[180 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cecbe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msdfs\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdfs' is not defined"
     ]
    }
   ],
   "source": [
    "sdfs['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b0f7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53f48b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p1': '../../results/evaluation_test/plots/scatter_agg_data.csv',\n",
       " 'p2': '../../results/evaluation_test/prediction_pooled_subsampled/max/plots/scatter_agg_data.csv',\n",
       " 'p3': '../../results/finetuning/evaluation_test/plots/scatter_agg_data.csv',\n",
       " 'p4': '../../results/finetuning/evaluation_test/baseline/plots/scatter_agg_data.csv',\n",
       " 'p5': '../../results/finetuning_0_20/evaluation_test/plots/scatter_agg_data.csv',\n",
       " 'p6': '../../results/finetuning_0_20/evaluation_test/baseline/plots/scatter_agg_data.csv',\n",
       " 'p7': '../../results/finetuning/evaluation_test/prediction_pooled_subsampled/max/plots/scatter_agg_data.csv'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4992cf",
   "metadata": {},
   "source": [
    "## load scatter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87aaa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfs = {key: pd.read_csv(val) for key,val in scatter_paths.items()} #scatter dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a83f8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to attn model:\n",
    "keys = ['p1', 'p2']\n",
    "for key in keys:\n",
    "    dfs[key] = dfs[key].query(\"model == 'AttentionModel'\")\n",
    "    sdfs[key] = sdfs[key].query(\"model.str.contains('attn')\") #different versions of attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff1874e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs = {}\n",
    "for k in dfs.keys():\n",
    "    full_dfs[k] = pd.merge(dfs[k], sdfs[k], on=['train_dataset', 'eval_dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b4c1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in full_dfs.keys():\n",
    "    full_dfs[k] = full_dfs[k].rename(columns=\n",
    "        {'x_mean': 'earliness_mean', \n",
    "         'x_std': 'earliness_std', \n",
    "         'y_mean': 'precision_mean', \n",
    "         'y_std': 'precision_std' }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6859772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(full_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c288433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AttentionModel'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68914967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we look at the attn model:\n",
    "df = df.query(\"model_x == 'AttentionModel'\")\n",
    "# drop obsolete dataset (too heterogenous / low quality)\n",
    "df = df.query(\"train_dataset != 'emory' & eval_dataset != 'emory'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1de4b861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">p1</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.055</td>\n",
       "      <td>0.079844</td>\n",
       "      <td>0.531098</td>\n",
       "      <td>0.022103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698006</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.755</td>\n",
       "      <td>1.246044</td>\n",
       "      <td>0.244710</td>\n",
       "      <td>0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.733108</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.220</td>\n",
       "      <td>1.072147</td>\n",
       "      <td>0.270946</td>\n",
       "      <td>0.012086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.235</td>\n",
       "      <td>1.187908</td>\n",
       "      <td>0.227974</td>\n",
       "      <td>0.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.731821</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.455</td>\n",
       "      <td>1.525451</td>\n",
       "      <td>0.254022</td>\n",
       "      <td>0.010373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.802502</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.625</td>\n",
       "      <td>1.212693</td>\n",
       "      <td>0.321037</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.705312</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.680</td>\n",
       "      <td>1.153581</td>\n",
       "      <td>0.252045</td>\n",
       "      <td>0.018139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.115</td>\n",
       "      <td>0.273633</td>\n",
       "      <td>0.243277</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.806525</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.613239</td>\n",
       "      <td>0.327414</td>\n",
       "      <td>0.035004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.918286</td>\n",
       "      <td>0.241868</td>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.834322</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.130384</td>\n",
       "      <td>0.363912</td>\n",
       "      <td>0.008250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.915253</td>\n",
       "      <td>0.205877</td>\n",
       "      <td>0.007570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.798606</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.825</td>\n",
       "      <td>1.902383</td>\n",
       "      <td>0.315987</td>\n",
       "      <td>0.049013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.753329</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.590</td>\n",
       "      <td>1.004459</td>\n",
       "      <td>0.283009</td>\n",
       "      <td>0.010858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.694860</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.237810</td>\n",
       "      <td>0.009988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.831972</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.365</td>\n",
       "      <td>0.236907</td>\n",
       "      <td>0.356650</td>\n",
       "      <td>0.006018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p2</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.844911</td>\n",
       "      <td>0.368059</td>\n",
       "      <td>0.029036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.759670</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.178638</td>\n",
       "      <td>0.285484</td>\n",
       "      <td>0.011018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.282332</td>\n",
       "      <td>0.265123</td>\n",
       "      <td>0.010473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.720870</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.365</td>\n",
       "      <td>0.449514</td>\n",
       "      <td>0.252695</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">p3</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.219375</td>\n",
       "      <td>0.283055</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.792255</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.275</td>\n",
       "      <td>0.269838</td>\n",
       "      <td>0.314837</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.786427</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.085</td>\n",
       "      <td>0.271339</td>\n",
       "      <td>0.294975</td>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.873594</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.850</td>\n",
       "      <td>1.014889</td>\n",
       "      <td>0.446497</td>\n",
       "      <td>0.040464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.765</td>\n",
       "      <td>0.621892</td>\n",
       "      <td>0.293611</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.789502</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.495</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.303076</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.140</td>\n",
       "      <td>1.011589</td>\n",
       "      <td>0.410842</td>\n",
       "      <td>0.035182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.761983</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.855</td>\n",
       "      <td>0.733655</td>\n",
       "      <td>0.286573</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.675</td>\n",
       "      <td>0.446864</td>\n",
       "      <td>0.303278</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.546580</td>\n",
       "      <td>0.487837</td>\n",
       "      <td>0.020819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793121</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.980</td>\n",
       "      <td>0.758782</td>\n",
       "      <td>0.321017</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.797083</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.304273</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p4</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>6.875</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.399529</td>\n",
       "      <td>0.017069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.729738</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>8.320</td>\n",
       "      <td>0.499187</td>\n",
       "      <td>0.256771</td>\n",
       "      <td>0.003817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.787233</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.135</td>\n",
       "      <td>0.266693</td>\n",
       "      <td>0.302023</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.782670</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.825</td>\n",
       "      <td>0.298957</td>\n",
       "      <td>0.295055</td>\n",
       "      <td>0.004809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">p5</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.555</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.252831</td>\n",
       "      <td>0.003548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.774966</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>6.220</td>\n",
       "      <td>0.566348</td>\n",
       "      <td>0.301949</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.699866</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.645</td>\n",
       "      <td>1.332807</td>\n",
       "      <td>0.234105</td>\n",
       "      <td>0.015405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.195</td>\n",
       "      <td>1.059835</td>\n",
       "      <td>0.303952</td>\n",
       "      <td>0.071046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.729016</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0.806730</td>\n",
       "      <td>0.264214</td>\n",
       "      <td>0.006479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.724120</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.915</td>\n",
       "      <td>0.277038</td>\n",
       "      <td>0.246401</td>\n",
       "      <td>0.009146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.844473</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.175</td>\n",
       "      <td>0.653357</td>\n",
       "      <td>0.380352</td>\n",
       "      <td>0.021274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.742710</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.690</td>\n",
       "      <td>1.025549</td>\n",
       "      <td>0.263921</td>\n",
       "      <td>0.008179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.737982</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.337722</td>\n",
       "      <td>0.255292</td>\n",
       "      <td>0.008648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.865</td>\n",
       "      <td>1.803781</td>\n",
       "      <td>0.386290</td>\n",
       "      <td>0.037804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.780288</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.257391</td>\n",
       "      <td>0.294014</td>\n",
       "      <td>0.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.782912</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.245</td>\n",
       "      <td>0.366742</td>\n",
       "      <td>0.305844</td>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p6</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>8.575</td>\n",
       "      <td>0.729512</td>\n",
       "      <td>0.327786</td>\n",
       "      <td>0.011386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.711287</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>8.350</td>\n",
       "      <td>0.385276</td>\n",
       "      <td>0.255480</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.763304</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.455</td>\n",
       "      <td>0.156525</td>\n",
       "      <td>0.287224</td>\n",
       "      <td>0.003679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.305</td>\n",
       "      <td>0.207214</td>\n",
       "      <td>0.267340</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p7</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.470225</td>\n",
       "      <td>0.479475</td>\n",
       "      <td>0.019430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.770197</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.260</td>\n",
       "      <td>0.687750</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.779573</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.840</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.795438</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.450</td>\n",
       "      <td>0.244310</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>0.006718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p1 0   AttentionModel          aumc         aumc  0.917711  0.003569   \n",
       "   1   AttentionModel          aumc         eicu  0.698006  0.010686   \n",
       "   3   AttentionModel          aumc        hirid  0.733108  0.013438   \n",
       "   4   AttentionModel          aumc        mimic  0.685606  0.013133   \n",
       "   5   AttentionModel          eicu         aumc  0.731821  0.007108   \n",
       "   6   AttentionModel          eicu         eicu  0.802502  0.003536   \n",
       "   8   AttentionModel          eicu        hirid  0.705312  0.026872   \n",
       "   9   AttentionModel          eicu        mimic  0.714940  0.009202   \n",
       "   15  AttentionModel         hirid         aumc  0.806525  0.014401   \n",
       "   16  AttentionModel         hirid         eicu  0.705568  0.009348   \n",
       "   18  AttentionModel         hirid        hirid  0.834322  0.002237   \n",
       "   19  AttentionModel         hirid        mimic  0.648077  0.012512   \n",
       "   20  AttentionModel         mimic         aumc  0.798606  0.022978   \n",
       "   21  AttentionModel         mimic         eicu  0.753329  0.007784   \n",
       "   23  AttentionModel         mimic        hirid  0.694860  0.010384   \n",
       "   24  AttentionModel         mimic        mimic  0.831972  0.003256   \n",
       "p2 0   AttentionModel        pooled         aumc  0.835573  0.010908   \n",
       "   1   AttentionModel        pooled         eicu  0.759670  0.006823   \n",
       "   2   AttentionModel        pooled        hirid  0.729156  0.013789   \n",
       "   3   AttentionModel        pooled        mimic  0.720870  0.005167   \n",
       "p3 0   AttentionModel          aumc         eicu  0.756370  0.007211   \n",
       "   1   AttentionModel          aumc        hirid  0.792255  0.002184   \n",
       "   2   AttentionModel          aumc        mimic  0.786427  0.002008   \n",
       "   3   AttentionModel          eicu         aumc  0.873594  0.016944   \n",
       "   4   AttentionModel          eicu        hirid  0.774104  0.001855   \n",
       "   5   AttentionModel          eicu        mimic  0.789502  0.002433   \n",
       "   6   AttentionModel         hirid         aumc  0.867947  0.010989   \n",
       "   7   AttentionModel         hirid         eicu  0.761983  0.004556   \n",
       "   8   AttentionModel         hirid        mimic  0.794380  0.002116   \n",
       "   9   AttentionModel         mimic         aumc  0.894071  0.003426   \n",
       "   10  AttentionModel         mimic         eicu  0.793121  0.003726   \n",
       "   11  AttentionModel         mimic        hirid  0.797083  0.004061   \n",
       "p4 0   AttentionModel          aumc         aumc  0.829317  0.004322   \n",
       "   1   AttentionModel          eicu         eicu  0.729738  0.005943   \n",
       "   2   AttentionModel         hirid        hirid  0.787233  0.001456   \n",
       "   3   AttentionModel         mimic        mimic  0.782670  0.002296   \n",
       "p5 0   AttentionModel          aumc         eicu  0.724866  0.003635   \n",
       "   1   AttentionModel          aumc        hirid  0.774966  0.002813   \n",
       "   2   AttentionModel          aumc        mimic  0.699866  0.023450   \n",
       "   3   AttentionModel          eicu         aumc  0.773791  0.041005   \n",
       "   4   AttentionModel          eicu        hirid  0.729016  0.010541   \n",
       "   5   AttentionModel          eicu        mimic  0.724120  0.011153   \n",
       "   6   AttentionModel         hirid         aumc  0.844473  0.011185   \n",
       "   7   AttentionModel         hirid         eicu  0.742710  0.006265   \n",
       "   8   AttentionModel         hirid        mimic  0.737982  0.009524   \n",
       "   9   AttentionModel         mimic         aumc  0.843931  0.013971   \n",
       "   10  AttentionModel         mimic         eicu  0.780288  0.002248   \n",
       "   11  AttentionModel         mimic        hirid  0.782912  0.003641   \n",
       "p6 0   AttentionModel          aumc         aumc  0.807556  0.006384   \n",
       "   1   AttentionModel          eicu         eicu  0.711287  0.003618   \n",
       "   2   AttentionModel         hirid        hirid  0.763304  0.001136   \n",
       "   3   AttentionModel         mimic        mimic  0.745647  0.002570   \n",
       "p7 0   AttentionModel        pooled         aumc  0.883985  0.009676   \n",
       "   1   AttentionModel        pooled         eicu  0.770197  0.002738   \n",
       "   2   AttentionModel        pooled        hirid  0.779573  0.001816   \n",
       "   3   AttentionModel        pooled        mimic  0.795438  0.002163   \n",
       "\n",
       "       finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "p1 0       False     False              NaN   False  attn             4.055   \n",
       "   1       False     False              NaN   False  attn             3.755   \n",
       "   3       False     False              NaN   False  attn             3.220   \n",
       "   4       False     False              NaN   False  attn             4.235   \n",
       "   5       False     False              NaN   False  attn             3.455   \n",
       "   6       False     False              NaN   False  attn             4.625   \n",
       "   8       False     False              NaN   False  attn             2.680   \n",
       "   9       False     False              NaN   False  attn             4.115   \n",
       "   15      False     False              NaN   False  attn             1.280   \n",
       "   16      False     False              NaN   False  attn             2.930   \n",
       "   18      False     False              NaN   False  attn             2.770   \n",
       "   19      False     False              NaN   False  attn             3.090   \n",
       "   20      False     False              NaN   False  attn             2.825   \n",
       "   21      False     False              NaN   False  attn             3.590   \n",
       "   23      False     False              NaN   False  attn             0.905   \n",
       "   24      False     False              NaN   False  attn             3.365   \n",
       "p2 0       False     False              NaN    True  attn             0.955   \n",
       "   1       False     False              NaN    True  attn             1.470   \n",
       "   2       False     False              NaN    True  attn             1.225   \n",
       "   3       False     False              NaN    True  attn             3.365   \n",
       "p3 0        True     False             0.10   False  attn             3.375   \n",
       "   1        True     False             0.10   False  attn             4.275   \n",
       "   2        True     False             0.10   False  attn             4.085   \n",
       "   3        True     False             0.10   False  attn             2.850   \n",
       "   4        True     False             0.10   False  attn             2.765   \n",
       "   5        True     False             0.10   False  attn             3.495   \n",
       "   6        True     False             0.10   False  attn             3.140   \n",
       "   7        True     False             0.10   False  attn             2.855   \n",
       "   8        True     False             0.10   False  attn             2.675   \n",
       "   9        True     False             0.10   False  attn             1.500   \n",
       "   10       True     False             0.10   False  attn             3.980   \n",
       "   11       True     False             0.10   False  attn             2.405   \n",
       "p4 0       False      True             0.10   False  attn             6.875   \n",
       "   1       False      True             0.10   False  attn             8.320   \n",
       "   2       False      True             0.10   False  attn             4.135   \n",
       "   3       False      True             0.10   False  attn             4.825   \n",
       "p5 0        True     False             0.02   False  attn             5.555   \n",
       "   1        True     False             0.02   False  attn             6.220   \n",
       "   2        True     False             0.02   False  attn             3.645   \n",
       "   3        True     False             0.02   False  attn             3.195   \n",
       "   4        True     False             0.02   False  attn             1.910   \n",
       "   5        True     False             0.02   False  attn             3.915   \n",
       "   6        True     False             0.02   False  attn             2.175   \n",
       "   7        True     False             0.02   False  attn             4.690   \n",
       "   8        True     False             0.02   False  attn             1.555   \n",
       "   9        True     False             0.02   False  attn             2.865   \n",
       "   10       True     False             0.02   False  attn             5.125   \n",
       "   11       True     False             0.02   False  attn             1.245   \n",
       "p6 0       False      True             0.02   False  attn             8.575   \n",
       "   1       False      True             0.02   False  attn             8.350   \n",
       "   2       False      True             0.02   False  attn             5.455   \n",
       "   3       False      True             0.02   False  attn             5.305   \n",
       "p7 0        True     False             0.10    True  attn             2.000   \n",
       "   1        True     False             0.10    True  attn             3.260   \n",
       "   2        True     False             0.10    True  attn             2.840   \n",
       "   3        True     False             0.10    True  attn             3.450   \n",
       "\n",
       "       earliness_std  precision_mean  precision_std  \n",
       "p1 0        0.079844        0.531098       0.022103  \n",
       "   1        1.246044        0.244710       0.007552  \n",
       "   3        1.072147        0.270946       0.012086  \n",
       "   4        1.187908        0.227974       0.008421  \n",
       "   5        1.525451        0.254022       0.010373  \n",
       "   6        1.212693        0.321037       0.010810  \n",
       "   8        1.153581        0.252045       0.018139  \n",
       "   9        0.273633        0.243277       0.004945  \n",
       "   15       0.613239        0.327414       0.035004  \n",
       "   16       0.918286        0.241868       0.008305  \n",
       "   18       0.130384        0.363912       0.008250  \n",
       "   19       0.915253        0.205877       0.007570  \n",
       "   20       1.902383        0.315987       0.049013  \n",
       "   21       1.004459        0.283009       0.010858  \n",
       "   23       0.942802        0.237810       0.009988  \n",
       "   24       0.236907        0.356650       0.006018  \n",
       "p2 0        0.844911        0.368059       0.029036  \n",
       "   1        1.178638        0.285484       0.011018  \n",
       "   2        1.282332        0.265123       0.010473  \n",
       "   3        0.449514        0.252695       0.004614  \n",
       "p3 0        1.219375        0.283055       0.010133  \n",
       "   1        0.269838        0.314837       0.004383  \n",
       "   2        0.271339        0.294975       0.002620  \n",
       "   3        1.014889        0.446497       0.040464  \n",
       "   4        0.621892        0.293611       0.003086  \n",
       "   5        0.361594        0.303076       0.006224  \n",
       "   6        1.011589        0.410842       0.035182  \n",
       "   7        0.733655        0.286573       0.006346  \n",
       "   8        0.446864        0.303278       0.005638  \n",
       "   9        0.546580        0.487837       0.020819  \n",
       "   10       0.758782        0.321017       0.008107  \n",
       "   11       0.361594        0.304273       0.005657  \n",
       "p4 0        0.334944        0.399529       0.017069  \n",
       "   1        0.499187        0.256771       0.003817  \n",
       "   2        0.266693        0.302023       0.003675  \n",
       "   3        0.298957        0.295055       0.004809  \n",
       "p5 0        0.649134        0.252831       0.003548  \n",
       "   1        0.566348        0.301949       0.005359  \n",
       "   2        1.332807        0.234105       0.015405  \n",
       "   3        1.059835        0.303952       0.071046  \n",
       "   4        0.806730        0.264214       0.006479  \n",
       "   5        0.277038        0.246401       0.009146  \n",
       "   6        0.653357        0.380352       0.021274  \n",
       "   7        1.025549        0.263921       0.008179  \n",
       "   8        1.337722        0.255292       0.008648  \n",
       "   9        1.803781        0.386290       0.037804  \n",
       "   10       0.257391        0.294014       0.004669  \n",
       "   11       0.366742        0.305844       0.004670  \n",
       "p6 0        0.729512        0.327786       0.011386  \n",
       "   1        0.385276        0.255480       0.005198  \n",
       "   2        0.156525        0.287224       0.003679  \n",
       "   3        0.207214        0.267340       0.003602  \n",
       "p7 0        1.470225        0.479475       0.019430  \n",
       "   1        0.687750        0.293600       0.004886  \n",
       "   2        0.370220        0.303068       0.002332  \n",
       "   3        0.244310        0.309495       0.006718  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05b5ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df.query(\"train_dataset == eval_dataset & \\\n",
    "        finetuned == False & \\\n",
    "        train_dataset != 'pooled' & \\\n",
    "        baseline == False\"\n",
    ")\n",
    "assert len(df_int) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80e1eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p1</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.055</td>\n",
       "      <td>0.079844</td>\n",
       "      <td>0.531098</td>\n",
       "      <td>0.022103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.802502</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.625</td>\n",
       "      <td>1.212693</td>\n",
       "      <td>0.321037</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.834322</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.130384</td>\n",
       "      <td>0.363912</td>\n",
       "      <td>0.008250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.831972</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.365</td>\n",
       "      <td>0.236907</td>\n",
       "      <td>0.356650</td>\n",
       "      <td>0.006018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p1 0   AttentionModel          aumc         aumc  0.917711  0.003569   \n",
       "   6   AttentionModel          eicu         eicu  0.802502  0.003536   \n",
       "   18  AttentionModel         hirid        hirid  0.834322  0.002237   \n",
       "   24  AttentionModel         mimic        mimic  0.831972  0.003256   \n",
       "\n",
       "       finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "p1 0       False     False              NaN   False  attn             4.055   \n",
       "   6       False     False              NaN   False  attn             4.625   \n",
       "   18      False     False              NaN   False  attn             2.770   \n",
       "   24      False     False              NaN   False  attn             3.365   \n",
       "\n",
       "       earliness_std  precision_mean  precision_std  \n",
       "p1 0        0.079844        0.531098       0.022103  \n",
       "   6        1.212693        0.321037       0.010810  \n",
       "   18       0.130384        0.363912       0.008250  \n",
       "   24       0.236907        0.356650       0.006018  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa7f2994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/2948288264.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  auc_int_mean = df_int.mean(axis=0)['auc_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/2948288264.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  auc_int_std = df_int.std(axis=0)['auc_mean']\n"
     ]
    }
   ],
   "source": [
    "auc_int_mean = df_int.mean(axis=0)['auc_mean']\n",
    "auc_int_std = df_int.std(axis=0)['auc_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8e22a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliness_means = {}\n",
    "earliness_stds = {}\n",
    "precision_means = {}\n",
    "precision_stds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f204498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1228713345.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int'] = df_int.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1228713345.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int'] = df_int.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int'] = df_int.mean()['earliness_mean']\n",
    "earliness_stds['int'] = df_int.std()['earliness_mean']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee3bf103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e1a6c2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049551997380370444"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97280bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466267443625092"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_int_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc6f8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean pair-wise AUC (no finetuning, no pooling)\n",
    "auc_pw_mean = df.query(\"train_dataset != eval_dataset & finetuned == False & train_dataset != 'pooled' & baseline == False\")['auc_mean'].mean()\n",
    "auc_pw_std = df.query(\"train_dataset != eval_dataset & finetuned == False & train_dataset != 'pooled' & baseline == False\")['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d7d333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pw = df.query(\"train_dataset != eval_dataset & finetuned == False & train_dataset != 'pooled' & baseline == False\")\n",
    "assert len(df_pw) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47db0eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">p1</th>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698006</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.755</td>\n",
       "      <td>1.246044</td>\n",
       "      <td>0.244710</td>\n",
       "      <td>0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.733108</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.220</td>\n",
       "      <td>1.072147</td>\n",
       "      <td>0.270946</td>\n",
       "      <td>0.012086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.235</td>\n",
       "      <td>1.187908</td>\n",
       "      <td>0.227974</td>\n",
       "      <td>0.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.731821</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.455</td>\n",
       "      <td>1.525451</td>\n",
       "      <td>0.254022</td>\n",
       "      <td>0.010373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.705312</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.680</td>\n",
       "      <td>1.153581</td>\n",
       "      <td>0.252045</td>\n",
       "      <td>0.018139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.115</td>\n",
       "      <td>0.273633</td>\n",
       "      <td>0.243277</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.806525</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.613239</td>\n",
       "      <td>0.327414</td>\n",
       "      <td>0.035004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.918286</td>\n",
       "      <td>0.241868</td>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.915253</td>\n",
       "      <td>0.205877</td>\n",
       "      <td>0.007570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.798606</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.825</td>\n",
       "      <td>1.902383</td>\n",
       "      <td>0.315987</td>\n",
       "      <td>0.049013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.753329</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.590</td>\n",
       "      <td>1.004459</td>\n",
       "      <td>0.283009</td>\n",
       "      <td>0.010858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.694860</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.237810</td>\n",
       "      <td>0.009988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p1 1   AttentionModel          aumc         eicu  0.698006  0.010686   \n",
       "   3   AttentionModel          aumc        hirid  0.733108  0.013438   \n",
       "   4   AttentionModel          aumc        mimic  0.685606  0.013133   \n",
       "   5   AttentionModel          eicu         aumc  0.731821  0.007108   \n",
       "   8   AttentionModel          eicu        hirid  0.705312  0.026872   \n",
       "   9   AttentionModel          eicu        mimic  0.714940  0.009202   \n",
       "   15  AttentionModel         hirid         aumc  0.806525  0.014401   \n",
       "   16  AttentionModel         hirid         eicu  0.705568  0.009348   \n",
       "   19  AttentionModel         hirid        mimic  0.648077  0.012512   \n",
       "   20  AttentionModel         mimic         aumc  0.798606  0.022978   \n",
       "   21  AttentionModel         mimic         eicu  0.753329  0.007784   \n",
       "   23  AttentionModel         mimic        hirid  0.694860  0.010384   \n",
       "\n",
       "       finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "p1 1       False     False              NaN   False  attn             3.755   \n",
       "   3       False     False              NaN   False  attn             3.220   \n",
       "   4       False     False              NaN   False  attn             4.235   \n",
       "   5       False     False              NaN   False  attn             3.455   \n",
       "   8       False     False              NaN   False  attn             2.680   \n",
       "   9       False     False              NaN   False  attn             4.115   \n",
       "   15      False     False              NaN   False  attn             1.280   \n",
       "   16      False     False              NaN   False  attn             2.930   \n",
       "   19      False     False              NaN   False  attn             3.090   \n",
       "   20      False     False              NaN   False  attn             2.825   \n",
       "   21      False     False              NaN   False  attn             3.590   \n",
       "   23      False     False              NaN   False  attn             0.905   \n",
       "\n",
       "       earliness_std  precision_mean  precision_std  \n",
       "p1 1        1.246044        0.244710       0.007552  \n",
       "   3        1.072147        0.270946       0.012086  \n",
       "   4        1.187908        0.227974       0.008421  \n",
       "   5        1.525451        0.254022       0.010373  \n",
       "   8        1.153581        0.252045       0.018139  \n",
       "   9        0.273633        0.243277       0.004945  \n",
       "   15       0.613239        0.327414       0.035004  \n",
       "   16       0.918286        0.241868       0.008305  \n",
       "   19       0.915253        0.205877       0.007570  \n",
       "   20       1.902383        0.315987       0.049013  \n",
       "   21       1.004459        0.283009       0.010858  \n",
       "   23       0.942802        0.237810       0.009988  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "492f1303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1354249333.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['pw'] = df_pw.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1354249333.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['pw'] = df_pw.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['pw'] = df_pw.mean()['earliness_mean']\n",
    "earliness_stds['pw'] = df_pw.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39ed4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375, 'pw': 3.0066666666666664}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e84b1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7229798509928985"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_pw_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b6d664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean pooled AUC (no finetuning)\n",
    "auc_po_mean = df.query(\"train_dataset == 'pooled' & finetuned == False & baseline == False\")['auc_mean'].mean()\n",
    "auc_po_std = df.query(\"train_dataset == 'pooled' & finetuned == False & baseline == False\")['auc_mean'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "090135a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_po = df.query(\"train_dataset == 'pooled' & finetuned == False & baseline == False\")\n",
    "assert len(df_po) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e476a7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p2</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.844911</td>\n",
       "      <td>0.368059</td>\n",
       "      <td>0.029036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.759670</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.178638</td>\n",
       "      <td>0.285484</td>\n",
       "      <td>0.011018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.282332</td>\n",
       "      <td>0.265123</td>\n",
       "      <td>0.010473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.720870</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.365</td>\n",
       "      <td>0.449514</td>\n",
       "      <td>0.252695</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p2 0  AttentionModel        pooled         aumc  0.835573  0.010908   \n",
       "   1  AttentionModel        pooled         eicu  0.759670  0.006823   \n",
       "   2  AttentionModel        pooled        hirid  0.729156  0.013789   \n",
       "   3  AttentionModel        pooled        mimic  0.720870  0.005167   \n",
       "\n",
       "      finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "p2 0      False     False              NaN    True  attn             0.955   \n",
       "   1      False     False              NaN    True  attn             1.470   \n",
       "   2      False     False              NaN    True  attn             1.225   \n",
       "   3      False     False              NaN    True  attn             3.365   \n",
       "\n",
       "      earliness_std  precision_mean  precision_std  \n",
       "p2 0       0.844911        0.368059       0.029036  \n",
       "   1       1.178638        0.285484       0.011018  \n",
       "   2       1.282332        0.265123       0.010473  \n",
       "   3       0.449514        0.252695       0.004614  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37cc4a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/4184905722.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['po'] = df_po.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/4184905722.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['po'] = df_po.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['po'] = df_po.mean()['earliness_mean']\n",
    "earliness_stds['po'] = df_po.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2705d783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 0.8080261443790046, 'pw': 1.0195773039784077, 'po': 1.0945651724162737}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87d83fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7613171965323347"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_po_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0364e84",
   "metadata": {},
   "source": [
    "## finetuning on 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6caabc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean finetuned AUC 10% \n",
    "auc_ft10_mean = df.query(\"train_dataset != 'pooled' & finetuned == True & baseline == False & finetuning_size == 0.10\")['auc_mean'].mean()\n",
    "auc_ft10_std = df.query(\"train_dataset != 'pooled' & finetuned == True & baseline == False & finetuning_size == 0.10\")['auc_std'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac8cd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft(ft_size=0.10):\n",
    "    return df.query(\"train_dataset != 'pooled' & finetuned == True & baseline == False & finetuning_size == @ft_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d39fc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft10 = get_ft(0.10)\n",
    "auc_ft10_mean = df_ft10['auc_mean'].mean()\n",
    "auc_ft10_std = df_ft10['auc_mean'].std()\n",
    "assert len(df_ft10) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "116ff452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">p3</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.219375</td>\n",
       "      <td>0.283055</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.792255</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.275</td>\n",
       "      <td>0.269838</td>\n",
       "      <td>0.314837</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.786427</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.085</td>\n",
       "      <td>0.271339</td>\n",
       "      <td>0.294975</td>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.873594</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.850</td>\n",
       "      <td>1.014889</td>\n",
       "      <td>0.446497</td>\n",
       "      <td>0.040464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.765</td>\n",
       "      <td>0.621892</td>\n",
       "      <td>0.293611</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.789502</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.495</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.303076</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.140</td>\n",
       "      <td>1.011589</td>\n",
       "      <td>0.410842</td>\n",
       "      <td>0.035182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.761983</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.855</td>\n",
       "      <td>0.733655</td>\n",
       "      <td>0.286573</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.675</td>\n",
       "      <td>0.446864</td>\n",
       "      <td>0.303278</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.546580</td>\n",
       "      <td>0.487837</td>\n",
       "      <td>0.020819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793121</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.980</td>\n",
       "      <td>0.758782</td>\n",
       "      <td>0.321017</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.797083</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.304273</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p3 0   AttentionModel          aumc         eicu  0.756370  0.007211   \n",
       "   1   AttentionModel          aumc        hirid  0.792255  0.002184   \n",
       "   2   AttentionModel          aumc        mimic  0.786427  0.002008   \n",
       "   3   AttentionModel          eicu         aumc  0.873594  0.016944   \n",
       "   4   AttentionModel          eicu        hirid  0.774104  0.001855   \n",
       "   5   AttentionModel          eicu        mimic  0.789502  0.002433   \n",
       "   6   AttentionModel         hirid         aumc  0.867947  0.010989   \n",
       "   7   AttentionModel         hirid         eicu  0.761983  0.004556   \n",
       "   8   AttentionModel         hirid        mimic  0.794380  0.002116   \n",
       "   9   AttentionModel         mimic         aumc  0.894071  0.003426   \n",
       "   10  AttentionModel         mimic         eicu  0.793121  0.003726   \n",
       "   11  AttentionModel         mimic        hirid  0.797083  0.004061   \n",
       "\n",
       "       finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "p3 0        True     False              0.1   False  attn             3.375   \n",
       "   1        True     False              0.1   False  attn             4.275   \n",
       "   2        True     False              0.1   False  attn             4.085   \n",
       "   3        True     False              0.1   False  attn             2.850   \n",
       "   4        True     False              0.1   False  attn             2.765   \n",
       "   5        True     False              0.1   False  attn             3.495   \n",
       "   6        True     False              0.1   False  attn             3.140   \n",
       "   7        True     False              0.1   False  attn             2.855   \n",
       "   8        True     False              0.1   False  attn             2.675   \n",
       "   9        True     False              0.1   False  attn             1.500   \n",
       "   10       True     False              0.1   False  attn             3.980   \n",
       "   11       True     False              0.1   False  attn             2.405   \n",
       "\n",
       "       earliness_std  precision_mean  precision_std  \n",
       "p3 0        1.219375        0.283055       0.010133  \n",
       "   1        0.269838        0.314837       0.004383  \n",
       "   2        0.271339        0.294975       0.002620  \n",
       "   3        1.014889        0.446497       0.040464  \n",
       "   4        0.621892        0.293611       0.003086  \n",
       "   5        0.361594        0.303076       0.006224  \n",
       "   6        1.011589        0.410842       0.035182  \n",
       "   7        0.733655        0.286573       0.006346  \n",
       "   8        0.446864        0.303278       0.005638  \n",
       "   9        0.546580        0.487837       0.020819  \n",
       "   10       0.758782        0.321017       0.008107  \n",
       "   11       0.361594        0.304273       0.005657  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ffec95fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">p3</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.219375</td>\n",
       "      <td>0.283055</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.792255</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.275</td>\n",
       "      <td>0.269838</td>\n",
       "      <td>0.314837</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.786427</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.085</td>\n",
       "      <td>0.271339</td>\n",
       "      <td>0.294975</td>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.846289</td>\n",
       "      <td>0.050213</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.910</td>\n",
       "      <td>1.097953</td>\n",
       "      <td>0.405345</td>\n",
       "      <td>0.081347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.765</td>\n",
       "      <td>0.621892</td>\n",
       "      <td>0.293611</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.789502</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.495</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.303076</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.140</td>\n",
       "      <td>1.011589</td>\n",
       "      <td>0.410842</td>\n",
       "      <td>0.035182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.761983</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.855</td>\n",
       "      <td>0.733655</td>\n",
       "      <td>0.286573</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.675</td>\n",
       "      <td>0.446864</td>\n",
       "      <td>0.303278</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.546580</td>\n",
       "      <td>0.487837</td>\n",
       "      <td>0.020819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793121</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.980</td>\n",
       "      <td>0.758782</td>\n",
       "      <td>0.321017</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.797083</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.304273</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p3 0   AttentionModel          aumc         eicu  0.756370  0.007211   \n",
       "   1   AttentionModel          aumc        hirid  0.792255  0.002184   \n",
       "   2   AttentionModel          aumc        mimic  0.786427  0.002008   \n",
       "   3   AttentionModel          eicu         aumc  0.846289  0.050213   \n",
       "   4   AttentionModel          eicu        hirid  0.774104  0.001855   \n",
       "   5   AttentionModel          eicu        mimic  0.789502  0.002433   \n",
       "   6   AttentionModel         hirid         aumc  0.867947  0.010989   \n",
       "   7   AttentionModel         hirid         eicu  0.761983  0.004556   \n",
       "   8   AttentionModel         hirid        mimic  0.794380  0.002116   \n",
       "   9   AttentionModel         mimic         aumc  0.894071  0.003426   \n",
       "   10  AttentionModel         mimic         eicu  0.793121  0.003726   \n",
       "   11  AttentionModel         mimic        hirid  0.797083  0.004061   \n",
       "\n",
       "       finetuned  baseline  finetuning_size model_y  earliness_mean  \\\n",
       "p3 0        True     False              0.1  attn             3.375   \n",
       "   1        True     False              0.1  attn             4.275   \n",
       "   2        True     False              0.1  attn             4.085   \n",
       "   3        True     False              0.1  attn             2.910   \n",
       "   4        True     False              0.1  attn             2.765   \n",
       "   5        True     False              0.1  attn             3.495   \n",
       "   6        True     False              0.1  attn             3.140   \n",
       "   7        True     False              0.1  attn             2.855   \n",
       "   8        True     False              0.1  attn             2.675   \n",
       "   9        True     False              0.1  attn             1.500   \n",
       "   10       True     False              0.1  attn             3.980   \n",
       "   11       True     False              0.1  attn             2.405   \n",
       "\n",
       "       earliness_std  precision_mean  precision_std  \n",
       "p3 0        1.219375        0.283055       0.010133  \n",
       "   1        0.269838        0.314837       0.004383  \n",
       "   2        0.271339        0.294975       0.002620  \n",
       "   3        1.097953        0.405345       0.081347  \n",
       "   4        0.621892        0.293611       0.003086  \n",
       "   5        0.361594        0.303076       0.006224  \n",
       "   6        1.011589        0.410842       0.035182  \n",
       "   7        0.733655        0.286573       0.006346  \n",
       "   8        0.446864        0.303278       0.005638  \n",
       "   9        0.546580        0.487837       0.020819  \n",
       "   10       0.758782        0.321017       0.008107  \n",
       "   11       0.361594        0.304273       0.005657  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft10 #old run, with bug in line 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7ee5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/894474592.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['ft10'] = df_ft10.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/894474592.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['ft10'] = df_ft10.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['ft10'] = df_ft10.mean()['earliness_mean']\n",
    "earliness_stds['ft10'] = df_ft10.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d9c98ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375,\n",
       " 'pw': 3.0066666666666664,\n",
       " 'po': 1.7537500000000001,\n",
       " 'ft10': 3.116666666666667}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a18f78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067364255118971"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_ft10_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10821dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean baseline AUC (internally trained on finetuning data) 10% size\n",
    "auc_base10_mean = df.query(\"train_dataset != 'pooled' & finetuned == False & baseline == True & finetuning_size == 0.10\")['auc_mean'].mean()\n",
    "auc_base10_std =  df.query(\"train_dataset != 'pooled' & finetuned == False & baseline == True & finetuning_size == 0.10\")['auc_std'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5aac505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(ft_size=0.10):\n",
    "    return df.query(\"train_dataset != 'pooled' & finetuned == False & baseline == True & finetuning_size == @ft_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85318a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base10 = get_baseline(0.10)\n",
    "auc_base10_mean = df_base10['auc_mean'].mean()\n",
    "auc_base10_std = df_base10['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20bf5a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7822397449362146"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_base10_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "247a99e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_base2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_base2\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_base2' is not defined"
     ]
    }
   ],
   "source": [
    "df_base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0cbfcc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1832192828.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int10'] = df_base10.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1832192828.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int10'] = df_base10.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int10'] = df_base10.mean()['earliness_mean']\n",
    "earliness_stds['int10'] = df_base10.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e3d34e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 0.8080261443790046,\n",
       " 'pw': 1.0195773039784077,\n",
       " 'po': 1.0945651724162737,\n",
       " 'ft10': 0.785370015092288,\n",
       " 'int10': 1.9149298290015755}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_stds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5793918",
   "metadata": {},
   "source": [
    "## finetuning on 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da1f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft2 = get_ft(0.02)\n",
    "auc_ft2_mean = df_ft2['auc_mean'].mean()\n",
    "auc_ft2_std = df_ft2['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b502d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/2657514013.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['ft2'] = df_ft2.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/2657514013.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['ft2'] = df_ft2.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['ft2'] = df_ft2.mean()['earliness_mean']\n",
    "earliness_stds['ft2'] = df_ft2.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a9647c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375,\n",
       " 'pw': 3.0066666666666664,\n",
       " 'po': 1.7537500000000001,\n",
       " 'ft10': 3.116666666666667,\n",
       " 'int10': 6.03875,\n",
       " 'ft2': 3.507916666666667}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a04c0d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7632434823574795"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_ft2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f8408b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2 = get_baseline(0.02)\n",
    "auc_base2_mean = df_base2['auc_mean'].mean()\n",
    "auc_base2_std = df_base2['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c15a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1515663671.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int2'] = df_base2.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1515663671.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int2'] = df_base2.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int2'] = df_base2.mean()['earliness_mean']\n",
    "earliness_stds['int2'] = df_base2.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ab35cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569484196682784"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_base2_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32649602",
   "metadata": {},
   "source": [
    "## finetuned 10% with pooled preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e2c11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft10po = df.query(\"train_dataset == 'pooled' & finetuned == True & baseline == False\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "531bfc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">p7</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.470225</td>\n",
       "      <td>0.479475</td>\n",
       "      <td>0.019430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.770197</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.687750</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.779573</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.795438</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.244310</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>0.006718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "p7 0  AttentionModel        pooled         aumc  0.883985  0.009676   \n",
       "   1  AttentionModel        pooled         eicu  0.770197  0.002738   \n",
       "   2  AttentionModel        pooled        hirid  0.779573  0.001816   \n",
       "   3  AttentionModel        pooled        mimic  0.795438  0.002163   \n",
       "\n",
       "      finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "p7 0       True     False              0.1    True  attn              2.00   \n",
       "   1       True     False              0.1    True  attn              3.26   \n",
       "   2       True     False              0.1    True  attn              2.84   \n",
       "   3       True     False              0.1    True  attn              3.45   \n",
       "\n",
       "      earliness_std  precision_mean  precision_std  \n",
       "p7 0       1.470225        0.479475       0.019430  \n",
       "   1       0.687750        0.293600       0.004886  \n",
       "   2       0.370220        0.303068       0.002332  \n",
       "   3       0.244310        0.309495       0.006718  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft10po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6186ecab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc_ft_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [209]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m      2\u001b[0m x_pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m aucs \u001b[38;5;241m=\u001b[39m [auc_pw_mean, auc_po_mean, \u001b[43mauc_ft_mean\u001b[49m, auc_int_mean]\n\u001b[1;32m      4\u001b[0m stds \u001b[38;5;241m=\u001b[39m [auc_pw_std, auc_po_std, auc_ft_std, auc_int_std]\n\u001b[1;32m      6\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpair-wise\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpooled\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minternal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auc_ft_mean' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_pos = np.arange(4)\n",
    "aucs = [auc_pw_mean, auc_po_mean, auc_ft_mean, auc_int_mean]\n",
    "stds = [auc_pw_std, auc_po_std, auc_ft_std, auc_int_std]\n",
    "\n",
    "names = ['pair-wise', 'pooled', 'finetuning', 'internal']\n",
    "ax.bar(x_pos, aucs, yerr=stds, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylim(0.5,0.9)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(f'AUROC (mean $\\pm$ std)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "212428c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc_ft_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [139]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m      2\u001b[0m x_pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m aucs \u001b[38;5;241m=\u001b[39m [auc_pw_mean, auc_po_mean, \u001b[43mauc_ft_mean\u001b[49m, auc_int_mean]\n\u001b[1;32m      4\u001b[0m stds \u001b[38;5;241m=\u001b[39m [auc_pw_std, auc_po_std, auc_ft_std, auc_int_std]\n\u001b[1;32m      6\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpair-wise\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpooled\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minternal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auc_ft_mean' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_pos = np.arange(4)\n",
    "aucs = [auc_pw_mean, auc_po_mean, auc_ft_mean, auc_int_mean]\n",
    "stds = [auc_pw_std, auc_po_std, auc_ft_std, auc_int_std]\n",
    "\n",
    "names = ['pair-wise', 'pooled', 'finetuning', 'internal']\n",
    "ax.errorbar(x_pos, aucs, yerr=stds, ecolor='black', capsize=7, fmt='d', color='black')\n",
    "ax.set_ylim(0.7,0.9)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(f'AUROC (mean $\\pm$ std)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bf17138",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+200B (347523906.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [72]\u001b[0;36m\u001b[0m\n\u001b[0;31m    â€‹\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+200B\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c786767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(14.375, 0.5, 'AUROC (mean $\\\\pm$ std)')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_pos = np.arange(5)\n",
    "aucs = [auc_pw_mean, auc_po_mean, auc_ft_mean, auc_base_mean, auc_int_mean]\n",
    "stds = [auc_pw_std, auc_po_std, auc_ft_std, auc_base_std, auc_int_std]\n",
    "\n",
    "names = ['pair-wise', 'pooled', 'finetuning', 'internal-small', 'internal']\n",
    "ax.bar(x_pos, aucs, yerr=stds, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylim(0.7,0.9)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(f'AUROC (mean $\\pm$ std)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e029e17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Performance across datasets')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "x_pos = np.arange(7)\n",
    "aucs = [auc_pw_mean, auc_po_mean, auc_ft2_mean, auc_base2_mean, auc_ft10_mean, auc_base10_mean, auc_int_mean]\n",
    "stds = [auc_pw_std, auc_po_std, auc_ft2_std, auc_base2_std, auc_ft10_std, auc_base10_std, auc_int_std]\n",
    "\n",
    "names = ['pair-wise', 'pooled', 'finetuning-2%', 'internal-2%', 'finetuning-10%', 'internal-10%', 'internal']\n",
    "ax.errorbar(x_pos, aucs, yerr=stds, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "ax.set_ylim(0.65,0.9)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(f'AUROC (mean $\\pm$ std)')\n",
    "\n",
    "plt.plot((2,3), (auc_ft2_mean, auc_base2_mean), '--', color='black')\n",
    "plt.plot((4,5), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "plt.hlines(auc_int_mean, 0,6, color='black', linestyle='dotted')\n",
    "\n",
    "plt.title('Performance across datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fbaebfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b09e611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = {'p1': 'internal', \n",
    "           'p2': 'pooled', \n",
    "           'p3': 'finetuning-10%',\n",
    "           'p4': 'internal-10%',\n",
    "           'p5': 'finetuning-2%',\n",
    "           'p6': 'internal-2%',\n",
    "           'p7': 'finetuning-10%-pooled'\n",
    "}\n",
    "df['level_0'] = df['level_0'].apply(lambda x: mapping.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a1ecf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'level_0': 'task'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0d19529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>level_1</th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internal</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.055</td>\n",
       "      <td>0.079844</td>\n",
       "      <td>0.531098</td>\n",
       "      <td>0.022103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internal</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698006</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.755</td>\n",
       "      <td>1.246044</td>\n",
       "      <td>0.244710</td>\n",
       "      <td>0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>internal</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.733108</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.220</td>\n",
       "      <td>1.072147</td>\n",
       "      <td>0.270946</td>\n",
       "      <td>0.012086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>internal</td>\n",
       "      <td>4</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.235</td>\n",
       "      <td>1.187908</td>\n",
       "      <td>0.227974</td>\n",
       "      <td>0.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>internal</td>\n",
       "      <td>5</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.731821</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.455</td>\n",
       "      <td>1.525451</td>\n",
       "      <td>0.254022</td>\n",
       "      <td>0.010373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>internal</td>\n",
       "      <td>6</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.802502</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.625</td>\n",
       "      <td>1.212693</td>\n",
       "      <td>0.321037</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>internal</td>\n",
       "      <td>8</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.705312</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.680</td>\n",
       "      <td>1.153581</td>\n",
       "      <td>0.252045</td>\n",
       "      <td>0.018139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>internal</td>\n",
       "      <td>9</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.115</td>\n",
       "      <td>0.273633</td>\n",
       "      <td>0.243277</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>internal</td>\n",
       "      <td>15</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.806525</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.613239</td>\n",
       "      <td>0.327414</td>\n",
       "      <td>0.035004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>internal</td>\n",
       "      <td>16</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.918286</td>\n",
       "      <td>0.241868</td>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>internal</td>\n",
       "      <td>18</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.834322</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.130384</td>\n",
       "      <td>0.363912</td>\n",
       "      <td>0.008250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>internal</td>\n",
       "      <td>19</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.648077</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.915253</td>\n",
       "      <td>0.205877</td>\n",
       "      <td>0.007570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>internal</td>\n",
       "      <td>20</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.798606</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.825</td>\n",
       "      <td>1.902383</td>\n",
       "      <td>0.315987</td>\n",
       "      <td>0.049013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>internal</td>\n",
       "      <td>21</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.753329</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.590</td>\n",
       "      <td>1.004459</td>\n",
       "      <td>0.283009</td>\n",
       "      <td>0.010858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>internal</td>\n",
       "      <td>23</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.694860</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.942802</td>\n",
       "      <td>0.237810</td>\n",
       "      <td>0.009988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>internal</td>\n",
       "      <td>24</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.831972</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.365</td>\n",
       "      <td>0.236907</td>\n",
       "      <td>0.356650</td>\n",
       "      <td>0.006018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pooled</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.844911</td>\n",
       "      <td>0.368059</td>\n",
       "      <td>0.029036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pooled</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.759670</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.178638</td>\n",
       "      <td>0.285484</td>\n",
       "      <td>0.011018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pooled</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.282332</td>\n",
       "      <td>0.265123</td>\n",
       "      <td>0.010473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pooled</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.720870</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.365</td>\n",
       "      <td>0.449514</td>\n",
       "      <td>0.252695</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1.219375</td>\n",
       "      <td>0.283055</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.792255</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.275</td>\n",
       "      <td>0.269838</td>\n",
       "      <td>0.314837</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.786427</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.085</td>\n",
       "      <td>0.271339</td>\n",
       "      <td>0.294975</td>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.873594</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.850</td>\n",
       "      <td>1.014889</td>\n",
       "      <td>0.446497</td>\n",
       "      <td>0.040464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>4</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.765</td>\n",
       "      <td>0.621892</td>\n",
       "      <td>0.293611</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>5</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.789502</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.495</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.303076</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>6</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.140</td>\n",
       "      <td>1.011589</td>\n",
       "      <td>0.410842</td>\n",
       "      <td>0.035182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>7</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.761983</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.855</td>\n",
       "      <td>0.733655</td>\n",
       "      <td>0.286573</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>8</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.675</td>\n",
       "      <td>0.446864</td>\n",
       "      <td>0.303278</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>9</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.546580</td>\n",
       "      <td>0.487837</td>\n",
       "      <td>0.020819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>10</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793121</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.980</td>\n",
       "      <td>0.758782</td>\n",
       "      <td>0.321017</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>finetuning-10%</td>\n",
       "      <td>11</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.797083</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0.361594</td>\n",
       "      <td>0.304273</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>internal-10%</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>6.875</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.399529</td>\n",
       "      <td>0.017069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>internal-10%</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.729738</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>8.320</td>\n",
       "      <td>0.499187</td>\n",
       "      <td>0.256771</td>\n",
       "      <td>0.003817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>internal-10%</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.787233</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.135</td>\n",
       "      <td>0.266693</td>\n",
       "      <td>0.302023</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>internal-10%</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.782670</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.825</td>\n",
       "      <td>0.298957</td>\n",
       "      <td>0.295055</td>\n",
       "      <td>0.004809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.555</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.252831</td>\n",
       "      <td>0.003548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.774966</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>6.220</td>\n",
       "      <td>0.566348</td>\n",
       "      <td>0.301949</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.699866</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.645</td>\n",
       "      <td>1.332807</td>\n",
       "      <td>0.234105</td>\n",
       "      <td>0.015405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.195</td>\n",
       "      <td>1.059835</td>\n",
       "      <td>0.303952</td>\n",
       "      <td>0.071046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>4</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.729016</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0.806730</td>\n",
       "      <td>0.264214</td>\n",
       "      <td>0.006479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>5</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.724120</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.915</td>\n",
       "      <td>0.277038</td>\n",
       "      <td>0.246401</td>\n",
       "      <td>0.009146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>6</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.844473</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.175</td>\n",
       "      <td>0.653357</td>\n",
       "      <td>0.380352</td>\n",
       "      <td>0.021274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>7</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.742710</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.690</td>\n",
       "      <td>1.025549</td>\n",
       "      <td>0.263921</td>\n",
       "      <td>0.008179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>8</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.737982</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.337722</td>\n",
       "      <td>0.255292</td>\n",
       "      <td>0.008648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>9</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.865</td>\n",
       "      <td>1.803781</td>\n",
       "      <td>0.386290</td>\n",
       "      <td>0.037804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>10</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.780288</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.257391</td>\n",
       "      <td>0.294014</td>\n",
       "      <td>0.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>finetuning-2%</td>\n",
       "      <td>11</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.782912</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.245</td>\n",
       "      <td>0.366742</td>\n",
       "      <td>0.305844</td>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>internal-2%</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>8.575</td>\n",
       "      <td>0.729512</td>\n",
       "      <td>0.327786</td>\n",
       "      <td>0.011386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>internal-2%</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.711287</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>8.350</td>\n",
       "      <td>0.385276</td>\n",
       "      <td>0.255480</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>internal-2%</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.763304</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.455</td>\n",
       "      <td>0.156525</td>\n",
       "      <td>0.287224</td>\n",
       "      <td>0.003679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>internal-2%</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>5.305</td>\n",
       "      <td>0.207214</td>\n",
       "      <td>0.267340</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>finetuning-10%-pooled</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.470225</td>\n",
       "      <td>0.479475</td>\n",
       "      <td>0.019430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>finetuning-10%-pooled</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.770197</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.260</td>\n",
       "      <td>0.687750</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>finetuning-10%-pooled</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.779573</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.840</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>finetuning-10%-pooled</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.795438</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.450</td>\n",
       "      <td>0.244310</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>0.006718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     task  level_1         model_x train_dataset eval_dataset  \\\n",
       "0                internal        0  AttentionModel          aumc         aumc   \n",
       "1                internal        1  AttentionModel          aumc         eicu   \n",
       "2                internal        3  AttentionModel          aumc        hirid   \n",
       "3                internal        4  AttentionModel          aumc        mimic   \n",
       "4                internal        5  AttentionModel          eicu         aumc   \n",
       "5                internal        6  AttentionModel          eicu         eicu   \n",
       "6                internal        8  AttentionModel          eicu        hirid   \n",
       "7                internal        9  AttentionModel          eicu        mimic   \n",
       "8                internal       15  AttentionModel         hirid         aumc   \n",
       "9                internal       16  AttentionModel         hirid         eicu   \n",
       "10               internal       18  AttentionModel         hirid        hirid   \n",
       "11               internal       19  AttentionModel         hirid        mimic   \n",
       "12               internal       20  AttentionModel         mimic         aumc   \n",
       "13               internal       21  AttentionModel         mimic         eicu   \n",
       "14               internal       23  AttentionModel         mimic        hirid   \n",
       "15               internal       24  AttentionModel         mimic        mimic   \n",
       "16                 pooled        0  AttentionModel        pooled         aumc   \n",
       "17                 pooled        1  AttentionModel        pooled         eicu   \n",
       "18                 pooled        2  AttentionModel        pooled        hirid   \n",
       "19                 pooled        3  AttentionModel        pooled        mimic   \n",
       "20         finetuning-10%        0  AttentionModel          aumc         eicu   \n",
       "21         finetuning-10%        1  AttentionModel          aumc        hirid   \n",
       "22         finetuning-10%        2  AttentionModel          aumc        mimic   \n",
       "23         finetuning-10%        3  AttentionModel          eicu         aumc   \n",
       "24         finetuning-10%        4  AttentionModel          eicu        hirid   \n",
       "25         finetuning-10%        5  AttentionModel          eicu        mimic   \n",
       "26         finetuning-10%        6  AttentionModel         hirid         aumc   \n",
       "27         finetuning-10%        7  AttentionModel         hirid         eicu   \n",
       "28         finetuning-10%        8  AttentionModel         hirid        mimic   \n",
       "29         finetuning-10%        9  AttentionModel         mimic         aumc   \n",
       "30         finetuning-10%       10  AttentionModel         mimic         eicu   \n",
       "31         finetuning-10%       11  AttentionModel         mimic        hirid   \n",
       "32           internal-10%        0  AttentionModel          aumc         aumc   \n",
       "33           internal-10%        1  AttentionModel          eicu         eicu   \n",
       "34           internal-10%        2  AttentionModel         hirid        hirid   \n",
       "35           internal-10%        3  AttentionModel         mimic        mimic   \n",
       "36          finetuning-2%        0  AttentionModel          aumc         eicu   \n",
       "37          finetuning-2%        1  AttentionModel          aumc        hirid   \n",
       "38          finetuning-2%        2  AttentionModel          aumc        mimic   \n",
       "39          finetuning-2%        3  AttentionModel          eicu         aumc   \n",
       "40          finetuning-2%        4  AttentionModel          eicu        hirid   \n",
       "41          finetuning-2%        5  AttentionModel          eicu        mimic   \n",
       "42          finetuning-2%        6  AttentionModel         hirid         aumc   \n",
       "43          finetuning-2%        7  AttentionModel         hirid         eicu   \n",
       "44          finetuning-2%        8  AttentionModel         hirid        mimic   \n",
       "45          finetuning-2%        9  AttentionModel         mimic         aumc   \n",
       "46          finetuning-2%       10  AttentionModel         mimic         eicu   \n",
       "47          finetuning-2%       11  AttentionModel         mimic        hirid   \n",
       "48            internal-2%        0  AttentionModel          aumc         aumc   \n",
       "49            internal-2%        1  AttentionModel          eicu         eicu   \n",
       "50            internal-2%        2  AttentionModel         hirid        hirid   \n",
       "51            internal-2%        3  AttentionModel         mimic        mimic   \n",
       "52  finetuning-10%-pooled        0  AttentionModel        pooled         aumc   \n",
       "53  finetuning-10%-pooled        1  AttentionModel        pooled         eicu   \n",
       "54  finetuning-10%-pooled        2  AttentionModel        pooled        hirid   \n",
       "55  finetuning-10%-pooled        3  AttentionModel        pooled        mimic   \n",
       "\n",
       "    auc_mean   auc_std  finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "0   0.917711  0.003569      False     False              NaN   False  attn     \n",
       "1   0.698006  0.010686      False     False              NaN   False  attn     \n",
       "2   0.733108  0.013438      False     False              NaN   False  attn     \n",
       "3   0.685606  0.013133      False     False              NaN   False  attn     \n",
       "4   0.731821  0.007108      False     False              NaN   False  attn     \n",
       "5   0.802502  0.003536      False     False              NaN   False  attn     \n",
       "6   0.705312  0.026872      False     False              NaN   False  attn     \n",
       "7   0.714940  0.009202      False     False              NaN   False  attn     \n",
       "8   0.806525  0.014401      False     False              NaN   False  attn     \n",
       "9   0.705568  0.009348      False     False              NaN   False  attn     \n",
       "10  0.834322  0.002237      False     False              NaN   False  attn     \n",
       "11  0.648077  0.012512      False     False              NaN   False  attn     \n",
       "12  0.798606  0.022978      False     False              NaN   False  attn     \n",
       "13  0.753329  0.007784      False     False              NaN   False  attn     \n",
       "14  0.694860  0.010384      False     False              NaN   False  attn     \n",
       "15  0.831972  0.003256      False     False              NaN   False  attn     \n",
       "16  0.835573  0.010908      False     False              NaN    True  attn     \n",
       "17  0.759670  0.006823      False     False              NaN    True  attn     \n",
       "18  0.729156  0.013789      False     False              NaN    True  attn     \n",
       "19  0.720870  0.005167      False     False              NaN    True  attn     \n",
       "20  0.756370  0.007211       True     False             0.10   False  attn     \n",
       "21  0.792255  0.002184       True     False             0.10   False  attn     \n",
       "22  0.786427  0.002008       True     False             0.10   False  attn     \n",
       "23  0.873594  0.016944       True     False             0.10   False  attn     \n",
       "24  0.774104  0.001855       True     False             0.10   False  attn     \n",
       "25  0.789502  0.002433       True     False             0.10   False  attn     \n",
       "26  0.867947  0.010989       True     False             0.10   False  attn     \n",
       "27  0.761983  0.004556       True     False             0.10   False  attn     \n",
       "28  0.794380  0.002116       True     False             0.10   False  attn     \n",
       "29  0.894071  0.003426       True     False             0.10   False  attn     \n",
       "30  0.793121  0.003726       True     False             0.10   False  attn     \n",
       "31  0.797083  0.004061       True     False             0.10   False  attn     \n",
       "32  0.829317  0.004322      False      True             0.10   False  attn     \n",
       "33  0.729738  0.005943      False      True             0.10   False  attn     \n",
       "34  0.787233  0.001456      False      True             0.10   False  attn     \n",
       "35  0.782670  0.002296      False      True             0.10   False  attn     \n",
       "36  0.724866  0.003635       True     False             0.02   False  attn     \n",
       "37  0.774966  0.002813       True     False             0.02   False  attn     \n",
       "38  0.699866  0.023450       True     False             0.02   False  attn     \n",
       "39  0.773791  0.041005       True     False             0.02   False  attn     \n",
       "40  0.729016  0.010541       True     False             0.02   False  attn     \n",
       "41  0.724120  0.011153       True     False             0.02   False  attn     \n",
       "42  0.844473  0.011185       True     False             0.02   False  attn     \n",
       "43  0.742710  0.006265       True     False             0.02   False  attn     \n",
       "44  0.737982  0.009524       True     False             0.02   False  attn     \n",
       "45  0.843931  0.013971       True     False             0.02   False  attn     \n",
       "46  0.780288  0.002248       True     False             0.02   False  attn     \n",
       "47  0.782912  0.003641       True     False             0.02   False  attn     \n",
       "48  0.807556  0.006384      False      True             0.02   False  attn     \n",
       "49  0.711287  0.003618      False      True             0.02   False  attn     \n",
       "50  0.763304  0.001136      False      True             0.02   False  attn     \n",
       "51  0.745647  0.002570      False      True             0.02   False  attn     \n",
       "52  0.883985  0.009676       True     False             0.10    True  attn     \n",
       "53  0.770197  0.002738       True     False             0.10    True  attn     \n",
       "54  0.779573  0.001816       True     False             0.10    True  attn     \n",
       "55  0.795438  0.002163       True     False             0.10    True  attn     \n",
       "\n",
       "    earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "0            4.055       0.079844        0.531098       0.022103  \n",
       "1            3.755       1.246044        0.244710       0.007552  \n",
       "2            3.220       1.072147        0.270946       0.012086  \n",
       "3            4.235       1.187908        0.227974       0.008421  \n",
       "4            3.455       1.525451        0.254022       0.010373  \n",
       "5            4.625       1.212693        0.321037       0.010810  \n",
       "6            2.680       1.153581        0.252045       0.018139  \n",
       "7            4.115       0.273633        0.243277       0.004945  \n",
       "8            1.280       0.613239        0.327414       0.035004  \n",
       "9            2.930       0.918286        0.241868       0.008305  \n",
       "10           2.770       0.130384        0.363912       0.008250  \n",
       "11           3.090       0.915253        0.205877       0.007570  \n",
       "12           2.825       1.902383        0.315987       0.049013  \n",
       "13           3.590       1.004459        0.283009       0.010858  \n",
       "14           0.905       0.942802        0.237810       0.009988  \n",
       "15           3.365       0.236907        0.356650       0.006018  \n",
       "16           0.955       0.844911        0.368059       0.029036  \n",
       "17           1.470       1.178638        0.285484       0.011018  \n",
       "18           1.225       1.282332        0.265123       0.010473  \n",
       "19           3.365       0.449514        0.252695       0.004614  \n",
       "20           3.375       1.219375        0.283055       0.010133  \n",
       "21           4.275       0.269838        0.314837       0.004383  \n",
       "22           4.085       0.271339        0.294975       0.002620  \n",
       "23           2.850       1.014889        0.446497       0.040464  \n",
       "24           2.765       0.621892        0.293611       0.003086  \n",
       "25           3.495       0.361594        0.303076       0.006224  \n",
       "26           3.140       1.011589        0.410842       0.035182  \n",
       "27           2.855       0.733655        0.286573       0.006346  \n",
       "28           2.675       0.446864        0.303278       0.005638  \n",
       "29           1.500       0.546580        0.487837       0.020819  \n",
       "30           3.980       0.758782        0.321017       0.008107  \n",
       "31           2.405       0.361594        0.304273       0.005657  \n",
       "32           6.875       0.334944        0.399529       0.017069  \n",
       "33           8.320       0.499187        0.256771       0.003817  \n",
       "34           4.135       0.266693        0.302023       0.003675  \n",
       "35           4.825       0.298957        0.295055       0.004809  \n",
       "36           5.555       0.649134        0.252831       0.003548  \n",
       "37           6.220       0.566348        0.301949       0.005359  \n",
       "38           3.645       1.332807        0.234105       0.015405  \n",
       "39           3.195       1.059835        0.303952       0.071046  \n",
       "40           1.910       0.806730        0.264214       0.006479  \n",
       "41           3.915       0.277038        0.246401       0.009146  \n",
       "42           2.175       0.653357        0.380352       0.021274  \n",
       "43           4.690       1.025549        0.263921       0.008179  \n",
       "44           1.555       1.337722        0.255292       0.008648  \n",
       "45           2.865       1.803781        0.386290       0.037804  \n",
       "46           5.125       0.257391        0.294014       0.004669  \n",
       "47           1.245       0.366742        0.305844       0.004670  \n",
       "48           8.575       0.729512        0.327786       0.011386  \n",
       "49           8.350       0.385276        0.255480       0.005198  \n",
       "50           5.455       0.156525        0.287224       0.003679  \n",
       "51           5.305       0.207214        0.267340       0.003602  \n",
       "52           2.000       1.470225        0.479475       0.019430  \n",
       "53           3.260       0.687750        0.293600       0.004886  \n",
       "54           2.840       0.370220        0.303068       0.002332  \n",
       "55           3.450       0.244310        0.309495       0.006718  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f83d3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='task', ylabel='auc_mean'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAE9CAYAAACY6h94AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAp90lEQVR4nO3de5hddX3v8fc39wuQCwkiTEIiRhHUcokBBZWIUMQq9VjbQIVi8aBHQeVIKz1ykKK1VmlprYgHASloiUitDRpAqkRRERMuAgkXIwEyXCQhIUIykEzyPX+sNbAZ5rKTmT17Zs379TzzZK/f+q21v3tl7b0/e10jM5EkSVJ1jGh2AZIkSepfBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqphRzS6gv0ybNi1nzZrV7DIkSZJ6deutt67NzOmNmn9lAt6sWbNYtmxZs8uQJEnqVUQ81Mj5u4tWkiSpYgx4kiRJFWPAkyRJqpiGBryIODoi7ouIlRFxZhfjZ0bEjRFxe0TcGRHH1Ix7fUTcHBHLI+KuiBjXyFolSZKqomEnWUTESOAC4EigFVgaEYsyc0VNt7OAqzLzwojYF1gMzIqIUcA3gRMy89cRsSuwpVG1SpIkVUkjt+DNA1Zm5gOZuRlYCBzbqU8Cu5SPJwGPlo+PAu7MzF8DZOaTmbm1gbVKkiRVRiMD3p7A6prh1rKt1jnA+yOilWLr3Wll+6uAjIjrI+K2iPjrBtYpSZJUKc0+yeI44LLMbAGOAa6IiBEUu44PA/68/Pc9EXFE54kj4pSIWBYRy9asWTOQdUuSJA1ajQx4jwAzaoZbyrZaJwNXAWTmzcA4YBrF1r6fZubazNxEsXXvwM5PkJkXZebczJw7fXrDLgYtSZI0pDTyThZLgTkRMZsi2C0Aju/U52HgCOCyiHgNRcBbA1wP/HVETAA2A28Fzm9grZIkaQg54ZJbaF3f1u34xze0sWVrMnpksPuk8d32a5kynitOPrgRJTZVwwJeZrZHxKkUYW0kcGlmLo+Ic4FlmbkI+CTw9Yg4neKEi5MyM4H1EfFPFCExgcWZ+YNG1SpJkoaW1vVtrFq7sdd+7duyrn5V09B70WbmYordq7VtZ9c8XgEc2s2036S4VIokSdKLtEzpfqscwOp1m2jflowaEcyYOmGH5zNUNTTgSZIkNUJvu1Xnn7eEVWs3MmPqBG484/CBKWoQafZZtJIkSepnBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsUY8CRJkirGgCdJklQxBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsUY8CRJkirGgCdJklQxBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsUY8CRJkirGgCdJklQxBjxJkqSKaWjAi4ijI+K+iFgZEWd2MX5mRNwYEbdHxJ0RcUwX45+JiDMaWackSVKVNCzgRcRI4ALgHcC+wHERsW+nbmcBV2XmAcAC4Kudxv8TcG2japQkSaqiRm7BmweszMwHMnMzsBA4tlOfBHYpH08CHu0YERF/DKwCljewRkmSpMppZMDbE1hdM9xattU6B3h/RLQCi4HTACJiJ+BTwN82sD5JkqRKavZJFscBl2VmC3AMcEVEjKAIfudn5jM9TRwRp0TEsohYtmbNmsZXK0mSNASMauC8HwFm1Ay3lG21TgaOBsjMmyNiHDANOBj4k4j4IjAZ2BYRz2bmV2onzsyLgIsA5s6dm414EZIkSUNNIwPeUmBORMymCHYLgOM79XkYOAK4LCJeA4wD1mTmmzs6RMQ5wDOdw50kSZK61rBdtJnZDpwKXA/cQ3G27PKIODci3l12+yTwPyPi18CVwEmZ6ZY4SZKkPmjkFjwyczHFyRO1bWfXPF4BHNrLPM5pSHGSJEkV1eyTLCRJktTPDHiSJEkVY8CTJEmqGAOeJElSxRjwJEmSKsaAJ0mSVDEGPEmSpIox4EmSJFWMAU+SJKliGnonC0mNd8Ilt9C6vq3b8Y9vaGPL1mT0yGD3SeO77dcyZTxXnHxwI0qUJA0wA540xLWub2PV2o299mvflnX1kyQNfQY8aYhrmdL9VjmA1es20b4tGTUimDF1wg7PR5I0dBjwpCGut92q889bwqq1G5kxdQI3nnH4wBQlSWoqT7KQJEmqGAOeJElSxRjwJEmSKsaAJ0mSVDEGPEmSpIox4EmSJFWMAU+SJKliDHiSJEkVY8CTJEmqGAOeJElSxRjwJEmSKsaAJ0mSVDEGPEmSpIox4EmSJFVMQwNeRBwdEfdFxMqIOLOL8TMj4saIuD0i7oyIY8r2IyPi1oi4q/z3bY2sU5IkqUpGNWrGETESuAA4EmgFlkbEosxcUdPtLOCqzLwwIvYFFgOzgLXAuzLz0Yh4LXA9sGejapUkSaqSRm7BmweszMwHMnMzsBA4tlOfBHYpH08CHgXIzNsz89GyfTkwPiLGNrBWSZKkymjYFjyKLW6ra4ZbgYM79TkH+GFEnAZMBN7exXzeC9yWmc81okhJkqSqafZJFscBl2VmC3AMcEVEPF9TROwH/APwoa4mjohTImJZRCxbs2bNgBQsSZI02DUy4D0CzKgZbinbap0MXAWQmTcD44BpABHRAvwncGJm/rarJ8jMizJzbmbOnT59ej+XL0mSNDQ1MuAtBeZExOyIGAMsABZ16vMwcARARLyGIuCtiYjJwA+AMzPz5w2sUZIkqXIadgxeZrZHxKkUZ8COBC7NzOURcS6wLDMXAZ8Evh4Rp1OccHFSZmY53SuBsyPi7HKWR2XmE42qV9Lwc8Ilt9C6vq3b8Y9vaGPL1mT0yGD3SeO77dcyZTxXnNz5EGNJap5GnmRBZi6muPRJbdvZNY9XAId2Md3ngM81sjZJal3fxqq1G3vt174t6+onSYNFQwOeJA1mLVO63yoHsHrdJtq3JaNGBDOmTtjh+UjSQDPgSRq2etutOv+8Jaxau5EZUydw4xmHD0xRktQPmn2ZFEmSJPUzA54kSVLFGPAkSZIqxoAnSZJUMQY8SZKkijHgSZIkVYwBT5IkqWIMeJIkSRVjwJMkSaoYA54kSVLFGPAkSZIqxoAnSZIqZd3GzTy3ZWuzy2iqUc0uQDrhkltoXd/W7fjHN7SxZWsyemSw+6Tx3fZrmTK+15vHDzebNrezuX1bs8uQpAHx5DPPcc41K7j2rsdo35YAPLahjd/87mnmvGznJlc3sAx4arrW9W2sWrux137t27KufoJnt2zli9fdx7eXPszGzcWv2EefamPZg+uYO2tqk6uTpP63aXM7Cy76Jb954pkXtT+7ZRvv+9rNLDr1MGbuOqFJ1Q08A56armVK91vlAFav20T7tmTUiGDG1O7fnL3NZ7jYti358DdvZcl9a17U/lz7No6/+BYWnnIIB86c0qTqJKkxrlq6+iXhrsNTbVv46pKVfOG9rx/gqprHgKem62236vzzlrBq7UZmTJ3AjWccPjBFDWE/W7n2JeGuw+b2bXzpuvu48pRDBrgqSWqs65Y/3uP4a+9+fFgFPE+ykCrm2rt7/pC7+YEneWrT5gGqRpIGRtuWno83bhtmJ10Y8KSK2bS5vY4+w+uDTlL17d8yqZfxkwemkEHCgCdVzOt7+RB72S5jedku4wamGEkaICe+aRajR0a34z/45tkDWE3zGfCkivmTA1uYNH50t+NPetNsRo7o/kNQkoaivafvxAXHH8iEMSNfMu7Md+zDUfvt3oSqmseAJ1XMpAmjufSkNzB1wpiXjFvwhhmc8pZXNKEqSWq8o/bbnV+c+TbOede+7DKuOI+0Zcp4PvzWvZtc2cAz4EkVdNBeU7jpU/P5/Htex87lh9wek8fxhfe+3q13kipt8oQxnHTobHbdaSwAo0cOz6gzPF+1NAxMHDuK4w+eybTyQ27sqJfutpAkVZMBT5IkqWIMeJIkSRVT950sIuJNwKzaaTLz8gbUJEmSpD6oawteRFwBnAccBryh/Jtbx3RHR8R9EbEyIs7sYvzMiLgxIm6PiDsj4piacX9TTndfRPxh3a9IkiRpmKt3C95cYN/MzHpnHBEjgQuAI4FWYGlELMrMFTXdzgKuyswLI2JfYDEwq3y8ANgP2AP474h4VWZ6+X1JkqRe1HsM3t3A9l4hcB6wMjMfyMzNwELg2E59EtilfDwJeLR8fCywMDOfy8xVwMpyfpIkSepFvVvwpgErIuJXwHMdjZn57h6m2RNYXTPcChzcqc85wA8j4jRgIvD2mml/2WnaPTs/QUScApwCMHPmzHpehyRJUuXVG/DOadDzHwdclpn/GBFvBK6IiNfWO3FmXgRcBDB37ty6dx9LkiRVWV0BLzN/sgPzfgSYUTPcUrbVOhk4unyOmyNiHMXWwnqmlSRJUhfqPYv2kIhYGhHPRMTmiNgaEb/vZbKlwJyImB0RYyhOmljUqc/DwBHlc7wGGAesKfstiIixETEbmAP8qv6XJUmSNHzVu4v2KxQB7TsUZ9SeCLyqpwkysz0iTgWuB0YCl2bm8og4F1iWmYuATwJfj4jTKU64OKk8U3d5RFwFrADagY96Bq0kSVJ96r7QcWaujIiRZdD6RkTcDvxNL9Msprj0SW3b2TWPVwCHdjPt3wF/V299kiRJKtQb8DaVu1nviIgvAo/hbc4kSZIGpXpD2gll31OBjRQnQLy3UUVJkiRpx9V7Fu1DETEeeHlm/m2Da5IkSVIf1HsW7buAO4DryuH9I6LzGbGSJEkaBOrdRXsOxa3CngLIzDuA2Q2pSJIkSX1Sb8DbkpkbOrV55whJkqRBqN6zaJdHxPHAyIiYA3wM+EXjypIkSdKOqncL3mnAfsBzwJXA74FPNKgmSZIk9UG9Z9FuAj5d/kmSpD464ZJbaF3f1u34xze0sWVrMnpksPuk8d32a5kynitOPrgRJWoIqyvgRcRc4P8As2qnyczXN6YsSZKqrXV9G6vWbuy1X/u2rKufVKveY/C+BfwVcBewrXHlSJI0PLRM6X6rHMDqdZto35aMGhHMmDphh+ej4anegLcmM73unSRJ/aS33arzz1vCqrUbmTF1AjeecfjAFKXKqDfgfSYiLgZ+RHGiBQCZ+d2GVCVJGvQ8hkwavOoNeB8A9gFG88Iu2gQMeJI0THkMmTR41Rvw3pCZr25oJZKkIcVjyKTBq96A94uI2DczVzS0GknSkOExZNLgVW/AOwS4IyJWURyDF0B6mZSCx6FIkqTBpN6Ad3RPIyNiSmau74d6hiSPQ5EkSYNJvXeyeKiXLj8CDux7OUOTx6FIkqTBpN4teL2JfprPkORxKJIkaTAZ0U/zyX6ajyRJkvqovwKeJEmSBon+CnjDehetpOq59aF1rH26uHHP2meeY/mjG5pckSTVr66AFxGHRMTONcO7RETtgWdH9HtlktQEmcm516zgvRfezNPPtQPw9LPtvPPLP+PCJb9tcnWSVJ96T7K4kBefJftMbVtmruvnuiTVqbfrMK5et+n5f+eft6Tbfl6HsXDNnY9x6c9XdTnuH667lwNmTuaQV+w6wFVJ0vapN+BFZj5/IkVmbouI/joDV1IfeB3G/nX5Lx7scfwVNz9kwJM06NUb0h6IiI9RbLUD+AjwQGNKkrQ9ert+4vbcSUVw/++e7tN4SRoM6g14Hwa+DJxFcUmUHwGn9DZRRBwN/AswErg4M7/Qafz5wPxycAKwW2ZOLsd9EXgnxXGCNwAfr92KKKngbtX+NWXiGH7/bHu34ydPGD2A1UjSjqn3ThZPAAu2Z8YRMRK4ADgSaAWWRsSizFxRM9/Ta/qfBhxQPn4TcCjQca/bnwFvBZZsTw2StL2O/YM9+PKPV3Y/fv89B7AaSdoxdQW8iPgGXVzMODP/sofJ5gErM/OBch4LgWOBFd30Pw74TMesgXHAGIpLsIwGfldPrZLUFye/+RUsvvtxVj7xzEvGHbTXFP7koJYmVCVJ26fe6+B9H/hB+fcjYBeKM2l7siewuma4tWx7iYjYC5gN/BggM28GbgQeK/+uz8x76qxVknbYpPGjuepDb+TEN+5FlFf4HBHw4bfuzeV/OY9xo0c2t0BJqkO9u2j/o3Y4Iq6k2G3aXxYAV2fm1nL+rwReA3T8VL4hIt6cmTd1quMUymMBZ86c2Y/lSBrOpk4cw7nHvpaf3r+GB5/cxMypEzjzHfs0uyxJqtuO3sliDrBbL30eAWbUDLeUbV1ZAFxZM/we4JeZ+UxmPgNcC7yx80SZeVFmzs3MudOnT6+7eEmqR5Sb8Dr+laShot47WTwdEb8v/zYA1wB/3ctkS4E5ETE7IsZQhLhFXcx7H2AKcHNN88PAWyNiVESMpjjBwl20kiRJdah3F+3OETGVYsvduI7mXqZpj4hTgespLpNyaWYuj4hzgWWZ2RH2FgALO10C5WrgbcBd5fNcl5nX1PuiJEmShrN6z6L9IPBxit2sdwCHUGxxe1tP02XmYmBxp7azOw2f08V0W4EP1VObJEmSXqzeY/A+DrwBeCgz51Ncr+6pRhUlSZKkHVdvwHs2M58FiIixmXkv8OrGlSVJkqQdVe+tylojYjLwPYpLlqwHHmpUUZIkSdpx9Z5k8Z7y4TkRcSMwCbiuYVVJkiT14IRLbqF1fVu341ev2/T8v/PPW9Jtv5Yp4yt5T+96t+A9LzN/0ohCJEmS6tW6vo1Vazf22q99W9bVr2q2O+BJkiQ1W8uU8T2Of3xDG1u2JqNHBrtP6r5vb/MZqgx4kiRpyKnibtX+tKO3KpMkSdIgZcCTJEmqGAOeJElSxRjwJEmSKsaAJ0mSVDEGPEmSpIox4EmSJFWMAU+SJKliDHiSJEkVY8CTJEmqGAOeJElSxRjwJEmSKsaAJ0mSVDEGPElSv9u2Ldncvq14nNnkaqThx4AnSepX1971GPP/cQmPPNUGwMNPbuLzi+95PvBJarxRzS5AklQdi+96jI9867YXtSVw0U8f4PENz/Ll4w5oTmHSMOMWPElSv9i2Lfnidfd2O37Rrx9l+aMbBrAiafgy4GnQevrZLVz281U8vuFZADa0bWFD25YmVyWpO/c/8TQPPrmpxz7XL//dAFUjDW8GPA1KDz25kaP/+SbOuWYFbVu2ArBu42aOOv8nrHzimSZXJ6krz27p/Ri758r3s6TGMuBp0MlMPr7wjucP0K71u98/x6n/fhvpWXnSoDNnt52YOGZkj30OmDllgKqRhreGBryIODoi7ouIlRFxZhfjz4+IO8q/+yPiqZpxMyPihxFxT0SsiIhZjaxVg8fdj/yeO1Y/1e34ex9/ml+tWjdwBUmqy8Sxo3j/IXt1O372tIm8/TW7DWBF0vDVsIAXESOBC4B3APsCx0XEvrV9MvP0zNw/M/cH/hX4bs3oy4EvZeZrgHnAE42qVYPLyjVP19HH3bTSYPTJo17Nsfvv8ZL2V0ybyDdOegOjRrrjSBoIjXynzQNWZuYDmbkZWAgc20P/44ArAcogOCozbwDIzGcys+cjd1UZkyeM6bXPlDr6SBp4Y0aN4F8WHMAPPnYYk8ePBmC3ncfyw9PfwqxpE5tcnTR8NDLg7QmsrhluLdteIiL2AmYDPy6bXgU8FRHfjYjbI+JL5RZBDQOH7j2NaTuN7Xb8LuNGMf/V7uaRBrP99pjElInFD7GJY0e55U4aYIPlHbcAuDozO06vGgW8GTgDeAPwCuCkzhNFxCkRsSwilq1Zs2agalWDjRk1gnOP3Y8R0fX4c969H+N7OZBbkqThrJEB7xFgRs1wS9nWlQWUu2dLrcAd5e7dduB7wIGdJ8rMizJzbmbOnT59ev9UrUHhmNe9nG+efDBvfMWuz7eNHTWCyz7wBv7HgS1NrEySGuvhJzfxue+v4NHySgIbNm32GqDabo0MeEuBORExOyLGUIS4RZ07RcQ+wBTg5k7TTo6IjtT2NmBFA2vVIPSmV07jylMOYdauEwDYY/J4DnfXrKQK+9lv1nLUP/+Ei3+2iufKe/eu27SFP/rXm54PfFI9Ghbwyi1vpwLXA/cAV2Xm8og4NyLeXdN1AbAway5sVu6qPQP4UUTcBQTw9UbVqsEtopt9tZJUIW2bt3Lalbd1ecHo1eva+Jvv3tWEqjRUjWrkzDNzMbC4U9vZnYbP6WbaG4DXN6w4SZIGkWvvfoz1m7rfFfuT+9ewet0mZkydMIBVaagaLCdZSJI0rD24dmOvfR5e5xXDVB8DXoNlJpvL4yi2bvP2WpKkrk3fufvLQ21PHwkMeA31i9+u5eh/vun5e6o+vG4TH7vydjb0sAlekjQ8vfP1ezBmVPdfy6/bcxJzdttpACvSUGbAa5BbH1rPX1z6K+773Ytvu7Xo149y4qW3sGXrSw+ilSQNX1MnjuGcd+3X5biJY0fyuT9+rSedqW4GvAY5/4b72bK1612yv27dwHV3Pz7AFUmSBrvjD57J5X85j8NeOY2OKLfT2JH810cP5Q9mTG5maRpiDHgNsGlzOz9bubbHPj9c8bsBqkaSNJS85VXT+eYHD37+3r3Tdx7HK3fbuclVaagx4DXAlvbeT6bY3L611z6SJEk7woDXALuMH8Xe0yf22OegvaYMUDWSJGm4MeA1QETwobfs3e34KRNG876DZnQ7XpIkqS8MeA3yvrktfOyIOYzodMLTbjuP5bIPzGPKxDHNKUySJFWeAa9BIoL/feSruOlTb2PqhNFAcYHKmz413zOhJElSQxnwGmzPyeOZNKHYWrfT2FGMHTWyyRVJkqSqM+BJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsUY8CRJkirGgCdJklQxBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFTOq2QVIUrOccMkttK5v63b86nWbnv93/nlLuu3XMmU8V5x8cH+XJ0k7zIAnadhqXd/GqrUbe+3Xvi3r6idJg4UBT9Kw1TJlfI/jH9/QxpatyeiRwe6Tuu/b23wkaaAZ8CQNW+5WlVRVnmQhSZJUMQ0NeBFxdETcFxErI+LMLsafHxF3lH/3R8RTncbvEhGtEfGVRtYpSZJUJQ3bRRsRI4ELgCOBVmBpRCzKzBUdfTLz9Jr+pwEHdJrNZ4GfNqpGSZKkKmrkMXjzgJWZ+QBARCwEjgVWdNP/OOAzHQMRcRDwMuA6YG4D65Qk7QAvMyMNXo0MeHsCq2uGW4Eu38ERsRcwG/hxOTwC+Efg/cDbu3uCiDgFOAVg5syZ/VK0JKk+XmZGGrwGy1m0C4CrM3NrOfwRYHFmtkZEtxNl5kXARQBz587NhlcpSXqel5mRBq9GBrxHgBk1wy1lW1cWAB+tGX4j8OaI+AiwEzAmIp7JzJecqCFJag53q0qDVyMD3lJgTkTMpgh2C4DjO3eKiH2AKcDNHW2Z+ec1408C5hruJEmS6tOwy6RkZjtwKnA9cA9wVWYuj4hzI+LdNV0XAAsz012skiRJ/aChx+Bl5mJgcae2szsNn9PLPC4DLuvn0iRJkirLO1lIkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsUY8CRJkirGgCdJklQxBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsUY8CRJkirGgCdJklQxBjxJkqSKMeBJkiRVjAFPkiSpYgx4kiRJFWPAkyRJqhgDniRJUsWManYB0gmX3ELr+rZux69et+n5f+eft6Tbfi1TxnPFyQf3d3mSJA05Bjw1Xev6Nlat3dhrv/ZtWVc/SRoK/HGrRjLgqelapozvcfzjG9rYsjUZPTLYfVL3fXubjyQNJv64VSMZ8NR0/vKUNBz541aNZMCTJKkJ/HGrRjLg9QOPo5AkSYNJQwNeRBwN/AswErg4M7/Qafz5wPxycAKwW2ZOjoj9gQuBXYCtwN9l5rcbWWtfeByFJEkaTBoW8CJiJHABcCTQCiyNiEWZuaKjT2aeXtP/NOCAcnATcGJm/iYi9gBujYjrM/OpRtXbFx5HIUmSBpNGbsGbB6zMzAcAImIhcCywopv+xwGfAcjM+zsaM/PRiHgCmA481cB6d5i7VSVJ0mDSyDtZ7AmsrhluLdteIiL2AmYDP+5i3DxgDPDbBtQoSZJUOYPlVmULgKszc2ttY0S8HLgC+EBmbus8UUScEhHLImLZmjVrBqhUSZKkwa2RAe8RYEbNcEvZ1pUFwJW1DRGxC/AD4NOZ+cuuJsrMizJzbmbOnT59ej+ULEmSNPQ1MuAtBeZExOyIGEMR4hZ17hQR+wBTgJtr2sYA/wlcnplXN7BGSZKkymlYwMvMduBU4HrgHuCqzFweEedGxLtrui4AFmZm1rT9KfAW4KSIuKP8279RtUqSJFVJvDhXDV1z587NZcuWNbsMSZKkXkXErZk5t1HzHywnWUiSJKmfGPAkSZIqxoAnSZJUMQY8SZKkiqnMSRYRsQZ4qNl19GAasLbZRQxhLr++cfntOJdd37j8+sbl1zeDefntlZkNu4hvZQLeYBcRyxp5tkzVufz6xuW341x2fePy6xuXX98M5+XnLlpJkqSKMeBJkiRVjAFv4FzU7AKGOJdf37j8dpzLrm9cfn3j8uubYbv8PAZPkiSpYtyCJ0mSVDEGvF5ExC/q6POJiJgwALUcHhHfb/TzDGYRsSQi6j4jqhnLLCI+FhH3RMT6iDhzB+cxOSI+0sc63r2jz9/N/K6LiKc6L8+ImB0Rt0TEyoj4dkSMKdtPi4i7I2JxTdthEXH+Djz3kHgfRsSp5XLIiJhW0x4R8eVy3J0RcWDZ/uqIuLVse2PZNioi/ruvr6WK62FE7B8RN0fE8nKZ/VnNuG+VbZ+vaTsrIv64P567Zp5DZV38VkTcV74HL42I0WX7e8vld1NE7FquJysjYnNV1pNyfk37vNqBWrf7e6qu78LM9K+Pf8CDwLTtnGbkDjzP4cD3m/16m7yslwBzB/MyA+4FWvo4j1nA3c1e3p1qOgJ4V+flCVwFLCgffw34X+XjX1L8iDyrnC6A64GpDaqv6e9D4IDy/+5FtQDHANeWy+AQ4Jay/Z+Aw4AW4D/KttOAk1wPu6znVcCc8vEewGPAZOD1wMVl+w3AJODlwDVNqnMwrIvHlOtbAFfWvC+XABOA95fr2r3A9zqWaxXWk7KmQf15Ve//Yw/TLKGX70K34PUiIp4p/z28TMxXR8S95a+jiIiPUXzQ3BgRN5Z9jyp/Zd4WEd+JiJ3K9gcj4h8i4jbgfeXw35b97oqIfcp+88rpb4+IX0TEq5v08vtNRMyqWW73lMtxQkQcUb7Ou8pfmWPL/l22d5pnd8v56PK5bgP+xwC/zq8BrwCujYjTI+IrZftlUWzB+UVEPBARf1IzzV9FxNJy68Pfls1fAPaOiDsi4kudf+FFxFci4qTycXfr0Um9PX9EjIiIr5bL64by1+vztdXKzB8BT3d6vQG8Dbi6bPo34I87RgOjKb5MtlB8oVybmet2YLkOifdhZt6emQ92MepY4PIs/BKYHBEvL5fLhI5lFBGTKb5cLt/eZdRpeVVyPczM+zPzN+XjR4EngOnlchwfESMo1rmtwLnAZ/qyHLsyhNbFxeX6lsCvKH5EAGwDxlKsc+8D9qb4kfFHVVlPytff8M+rss6vRcSyiLg/Iv6obB8XEd8oX9/tETG/p/ZO85wYxXfer8o+x5bt4yNiYRTfn/8JjO+urg4GvO1zAPAJYF+KD89DM/PLwKPA/MycH8VumbOAt2fmgcAy4H/XzOPJzDwwMxeWw2vLfhcCZ5Rt9wJvzswDgLOBz1MNrwa+mpmvAX5PsVwuA/4sM18HjAL+V0SM66q9dkbdLedy2q9TfEkeBOw+AK/reZn5Ycr1AVjfafTLKT9IKT4QiYijgDnAPGB/4KCIeAtwJvDbzNw/M/+qjqfuaj3q7CXPTxGAZ1Gs0ycAb6zjuWrtCjyVme3lcCuwZ/n4KxS/imcCPwc+AFywnfPvylB8H+4JrK4Z7lhOFwD/h+KL5vPA/wU+n5nb+vBcw2I9jIh5wJiyvnuANcBtwDXAK4ERmXlbHTX3xaBfF6PYNXsCcF3Z9PfAf1N8Rr4LaKfYqlzJ9aSTRnxezaJYHu8EvlZ+B30UyPL76zjg33ppr/Vp4MeZOY/i/fuliJhI8R24qfz+/AzF91uPRtVRvF7wq8xsBYiIOyj+Y3/Wqc8hFCvfz4sfC4wBbq4Z/+1O/b9b/nsrL2xtmkTxHz8HSIpfFVWwOjN/Xj7+JsWX2arMvL9s+zeKN8CN3bT/c828ulvO+5TT/gYgIr4JnNKoF7Sdvld+ca+IiJeVbUeVf7eXwztRfIA+vJ3z7mo9quf5DwO+U7Y/3rHFoT9k5hXAFQARcTbwZeAdEXEiRdj55A4Gmcq8DzPzYYrdM0TEKym2stwTEVeUNf/fmvdBfxny62EUWz+vAP6iYx3KzE/UjL8G+FBEfBr4A+CGzPz6dr6WegyFdfGrwE8z8yaAzLyBYjc25XuxjWIr3keBCfHCsYNDfj3ZHn34vLqqbP9NRDxA8R10GPCv5XzvjYiHKA4v6K691lHAuyOiI/iOowidbylrIjPvjIg7e3tNBrzt81zN4610vfyC4sPkuG7msbGbedbO77PAjZn5noiYRbGvvQo6X5PnKYpfVDuiy+UcEfvv4PwGQu36EzX//n1m/r/ajuX/e612XrzFvfOvvq7Wo3qev0sRcTDQUdPZmbmom65PUuxuHFX+Km4BHuk0rz2AeZl5bkT8hGIXyVkUx8jc0FMd3Rg078OIuB54GbAsMz/YQ82PADNqhl+ynIC/o1guHwMupjiO6/PAn/cw3x0xpNfDiNgF+AHw6XJ3d+dpjqUIDjsBe2fmn0bE9RHxrczc1NPz7YBBvS5GxGcodmF/qIv+E4CTKPamfIpiz8ef8sL6NqTXk2669unzKiIOp9hSR2buX07S+Xutr9eeC+C9mXlfp7q2e0buou0fTwM7l49/CRxa/hrv2J/eOaH3ZhIvrHQn9UuFg8PMKM8UBI6n2FUxq2NZUWxy/wlwXzfttbpbzveW0+5d9uvuQ3WwuB74y3jhmJw9I2I3XrxOATwE7BsRY6M4TuuIfnr+nwPvjeLYlpdRbk3KzFvK3S379/BhSXl8z41Ax3EwfwH8V6dun6XYrQTFcSNJcRxQf59lOODvw8z8w3IZ9RTuABYBJ0bhEGBDZj7WMTIi3go8Wm55nkCxfBqxjLozJNbDKM5u/E+K4xmv7jyTcnfkJ4Av8sK6BjCSYsvZQGn6uhgRHwT+EDiumy1Pf0W5RYgXAljS8zo3JNaT7ibu6+dVZn6643lq+r+vrGdvit309wE3UQbl8v96Zi/tta4HTosy0UXEAWX7Tym+N4mI11KcWNQjA17/uAi4LiJuzMw1FG/AK8tNqB27DbfHF4G/j4jbqdZW1vuAj0bEPcAU4HyK4xy+ExF3UbyJvpaZz3bVXjuj7pZzOe0pwA+iOHD5iQF5ZTsoM38I/Dtwc/larwZ2zswnKXbp3B0RX8rM1RRnf91d/nt7tzPdPv9BcRzKCord5rcBG7rqGBE3Ad+h+CXbGhF/WI76FMXxjysptsheUjPNAeXr7DgW6t+Bu4BDeeGYoP7S9PdhFJecaKXYMnBnRFxcjloMPACspNhS8pGaaYJiC8Fna17Hv1BspTpvO2veIUNoPfxTil1VJ0VxQP8dnbbafxT4t3JL3Z0UuxzvAm7NzKf6qdZ6NH1dpPjMfBnF/+kd5W5H4EVbqb5XNl1McVzXaynWgy4NofVkID+vHqY4ieVa4MPld9BXgRHlMvo2xVnxz/XQXuuzFLvg74yI5bzwuXAhsFP5/XkuxVbqHnknCw2IchP+9zPztc2uRS8WETtl5jMRsSvFB9Whmfl4s+vS8OJ6qHoMpvUkIi6j+F57ydbkwaBKW4ck7Zjvl7tRxgCf9UtVTeJ6qHq4ntTJLXiSJEkV4zF4kiRJFWPAkyRJqhgDniRJUsUY8CQNSxExOSI+0nvPLqd9MIpbUEnSoGTAkzRcTabmenSSVCUGPEnD1ReAvcuLwJ4fET+KiNsi4q4obnfVcdeBH0TEr8uLuP5Z7QwiYnxEXBsR/7Mpr0CSuuF18CQNV2cCr83M/SNiFMWtiH5f7nr9ZUQsAo6muIXYOwEiYlLN9DsBCylum3X5QBcvST1xC54kFTf4/nx5K6n/BvakuM3TXcCREfEPEfHmzKy9LdJ/Ad8w3EkajAx4klTcAHw6cFB5I/HfAeMy837gQIqg97na+3lS3Pj86I6bgkvSYGLAkzRcPQ3sXD6eBDyRmVsiYj6wFzx/U/ZNmflN4EsUYa/D2cB64IKBK1mS6mPAkzQsZeaTwM8j4m5gf2BuRNwFnAjcW3Z7HfCriLgD+AzwuU6z+TgwPiK+OCBFS1KdvBetJElSxbgFT5IkqWIMeJIkSRVjwJMkSaoYA54kSVLFGPAkSZIqxoAnSZJUMQY8SZKkijHgSZIkVcz/B3CY25PXurdSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.pointplot(x='task', y='auc_mean', data=df, join=False, capsize=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f50819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375,\n",
       " 'pw': 3.0066666666666664,\n",
       " 'po': 1.7537500000000001,\n",
       " 'ft10': 3.116666666666667,\n",
       " 'int10': 6.03875,\n",
       " 'ft2': 3.507916666666667,\n",
       " 'int2': 6.921249999999999}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7dba7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measure(df, func, measure):\n",
    "    return getattr(df, func)()[measure]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "923de1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8080261443790046"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_measure(df_int, 'std', 'earliness_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b54c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['int', 'pw', 'po', 'ft10', 'int10', 'ft2', 'int2', 'ft10po']\n",
    "df_ = [df_int, df_pw, df_po, df_ft10, df_base10, df_ft2, df_base2, df_ft10po]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e192ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    }
   ],
   "source": [
    "earliness_means = {}\n",
    "earliness_stds = {}\n",
    "for key, _df in zip(keys, df_):\n",
    "    earliness_means[key] = get_measure(_df, 'mean', 'earliness_mean')\n",
    "    earliness_stds[key] = get_measure(_df, 'std', 'earliness_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74974e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375,\n",
       " 'pw': 3.0066666666666664,\n",
       " 'po': 1.7537500000000001,\n",
       " 'ft10': 3.116666666666667,\n",
       " 'int10': 6.03875,\n",
       " 'ft2': 3.507916666666667,\n",
       " 'int2': 6.921249999999999,\n",
       " 'ft10po': 2.8875}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "95b4ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    }
   ],
   "source": [
    "precision_means = {}\n",
    "precision_stds = {}\n",
    "for key, _df in zip(keys, df_):\n",
    "    precision_means[key] = get_measure(_df, 'mean', 'precision_mean')\n",
    "    precision_stds[key] = get_measure(_df, 'std', 'precision_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0959b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    }
   ],
   "source": [
    "auc_means = {}\n",
    "auc_stds = {}\n",
    "for key, _df in zip(keys, df_):\n",
    "    auc_means[key] = get_measure(_df, 'mean', 'auc_mean')\n",
    "    auc_stds[key] = get_measure(_df, 'std', 'auc_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c6dd9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_sorted = ['pw', 'po', 'ft2', 'ft10', 'ft10po', 'int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "05c0d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_m = [auc_means[k] for k in keys_sorted]\n",
    "aucs_s = [auc_stds[k] for k in keys_sorted]\n",
    "earliness_m = [earliness_means[k] for k in keys_sorted]\n",
    "earliness_s = [earliness_stds[k] for k in keys_sorted]\n",
    "precision_m = [precision_means[k] for k in keys_sorted]\n",
    "precision_s = [precision_stds[k] for k in keys_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "51f49fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e0ad691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7229798509928985,\n",
       " 0.7613171965323347,\n",
       " 0.7632434823574795,\n",
       " 0.7569484196682784,\n",
       " 0.8044610478536885,\n",
       " 0.7822397449362146,\n",
       " 0.8466267443625092]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2d92f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3380255286.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_int['task'] = 'internal'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3380255286.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pw['task'] = 'pair-wise'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3380255286.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_po['task'] = 'pooled'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3380255286.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ft10['task'] = 'ft-10%'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3380255286.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ft2['task'] = 'ft-2%'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3380255286.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ft10po['task'] = 'ft-10%-pooled'\n"
     ]
    }
   ],
   "source": [
    "df_int['task'] = 'internal'\n",
    "df_pw['task'] = 'pair-wise' \n",
    "df_po['task'] = 'pooled'\n",
    "df_ft10['task'] = 'ft-10%' \n",
    "df_ft2['task'] = 'ft-2%'\n",
    "df_ft10po['task'] = 'ft-10%-pooled' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c13c74fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw values:\n",
    "df_tot = pd.concat([df_pw, df_po, df_ft2, df_ft10, df_ft10po, df_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bcb830cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/1196983362.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_ft10po.mean()['precision_mean']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.346409378294573"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft10po.mean()['precision_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1b5f1b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33560/3433370938.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_int.mean()['precision_mean']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3931742786496343"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_int.mean()['precision_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5979283b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,10))\n",
    "ax1 = plt.subplot(311)\n",
    "\n",
    "x_pos = np.arange(6) #7\n",
    "#aucs = [auc_pw_mean, auc_po_mean, auc_ft2_mean, auc_base2_mean, auc_ft10_mean, auc_base10_mean, auc_int_mean]\n",
    "#stds = [auc_pw_std, auc_po_std, auc_ft2_std, auc_base2_std, auc_ft10_std, auc_base10_std, auc_int_std]\n",
    "names = ['pair-wise', 'pooled', 'ft-2%',  'ft-10%', 'ft-10%-pooled', 'internal']\n",
    "ax1.errorbar(x_pos, aucs_m, yerr=aucs_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "sns.stripplot(x=\"task\", y=\"auc_mean\", data=df_tot, jitter=0.1, ax=ax1,alpha=0.5)\n",
    "\n",
    "ax1.set_ylim(0.60,0.93)\n",
    "\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(names)\n",
    "#ax[0].tight_layout()\n",
    "ax1.set_ylabel(f'AUROC')\n",
    "\n",
    "ax2 = plt.subplot(312, sharex= ax1)\n",
    "\n",
    "#plt.plot((2,3), (auc_ft2_mean, auc_base2_mean), '--', color='black')\n",
    "#plt.plot((4,5), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "#plt.hlines(auc_int_mean, 0,6, color='black', linestyle='dotted')\n",
    "sns.stripplot(x=\"task\", y=\"precision_mean\", data=df_tot, jitter=0.1, ax=ax2, alpha=0.5)\n",
    "ax2.errorbar(x_pos, precision_m, yerr=precision_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "ax2.set_ylabel(f'PPV @ 80% Sensitivity')\n",
    "ax2.set_ylim(0.15,0.55)\n",
    "\n",
    "#ax[1].set_xticklabels(names)\n",
    "#ax[1].tight_layout()\n",
    "\n",
    "ax3 = plt.subplot(313, sharex= ax1)\n",
    "sns.stripplot(x=\"task\", y=\"earliness_mean\", data=df_tot, jitter=0.1, ax=ax3, alpha=0.5)\n",
    "ax3.errorbar(x_pos, earliness_m, yerr=earliness_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "ax3.set_ylabel(f'Earliness @ 80% Sensitivity')\n",
    "#ax[2].set_xticklabels(names)\n",
    "ax3.set_ylim(-0.2,6.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "x1 = np.arange(7)\n",
    "y1 = np.array([0.13] * 7)\n",
    "for i,j, n in zip(x1,y1, aucs_m):\n",
    "    ax1.annotate(f'{n:.2f}',xy=(i-0.1,j+0.5), size=12)\n",
    "y2 = np.array([0.18] * 7)\n",
    "\n",
    "for i,j, n in zip(x1,y2, precision_m):\n",
    "    ax2.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)\n",
    "\n",
    "y3 = np.array([0.2] * 7)\n",
    "for i,j, n in zip(x1,y3, earliness_m):\n",
    "    ax3.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "606b8dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2587448972219523,\n",
       " 0.2928404749003678,\n",
       " 0.29076371654636074,\n",
       " 0.33748924406995057,\n",
       " 0.346409378294573,\n",
       " 0.3931742786496343]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb989ec",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- csv of these results\n",
    "- plot with increasingly smaller finetuning split\n",
    "- check nemati paper again\n",
    "- how much data collection can be prevented using pretraining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c6fda",
   "metadata": {},
   "source": [
    "# TO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
