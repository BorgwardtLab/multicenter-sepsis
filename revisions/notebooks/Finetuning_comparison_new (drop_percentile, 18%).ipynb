{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef23a78",
   "metadata": {},
   "source": [
    "# Notebook comparing finetuning results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29930456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48eccb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mbaseline\u001b[m\u001b[m/ \u001b[34mplots\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls ../results/finetuning_0_20/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "610265c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../results'\n",
    "paths = {\n",
    "# standard resutls (internal, external)\n",
    "'pairwise':'evaluation_test/plots/',\n",
    "# model pooling / ensembling:\n",
    "'pooled': 'evaluation_test/prediction_pooled_subsampled/max/plots/',\n",
    "# finetuned models on 10%:\n",
    "'ft10': 'finetuning/plots/',\n",
    "# baseline (of finetuning) on 10%:\n",
    "'int10': 'finetuning/baseline/plots/',\n",
    "# finetuned models on 2%:\n",
    "'ft2': 'finetuning_0_20/plots/',\n",
    "# baseline (of finetuning) on 2%:\n",
    "'int2': 'finetuning_0_20/baseline/plots/',\n",
    "# baseline (of finetuning) on 20%:\n",
    "'int20': 'finetuning_2_00/baseline/plots/',\n",
    "# baseline (of finetuning) on 30%:\n",
    "'int30': 'finetuning_3_00/baseline/plots/',\n",
    "# baseline (of finetuning) on 40%:\n",
    "'int40': 'finetuning_4_00/baseline/plots/',\n",
    "# baseline (of finetuning) on 50%:\n",
    "'int50': 'finetuning_5_00/baseline/plots/',\n",
    "}\n",
    "paths = {key: os.path.join(base_dir, val) for key, val in paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07ba4d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pairwise': '../results/evaluation_test/plots/',\n",
       " 'pooled': '../results/evaluation_test/prediction_pooled_subsampled/max/plots/',\n",
       " 'ft10': '../results/finetuning/plots/',\n",
       " 'int10': '../results/finetuning/baseline/plots/',\n",
       " 'ft2': '../results/finetuning_0_20/plots/',\n",
       " 'int2': '../results/finetuning_0_20/baseline/plots/',\n",
       " 'int20': '../results/finetuning_2_00/baseline/plots/',\n",
       " 'int30': '../results/finetuning_3_00/baseline/plots/',\n",
       " 'int40': '../results/finetuning_4_00/baseline/plots/',\n",
       " 'int50': '../results/finetuning_5_00/baseline/plots/'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6e4d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_paths = {key: os.path.join(path, 'roc_summary_subsampled.csv') for key, path in paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f80a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_paths = {key: os.path.join(path, 'scatter_agg_data.csv') for key, path in paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "364fe85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key: pd.read_csv(val) for key,val in roc_paths.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9419aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key: df.drop(columns='Unnamed: 0') for key, df in dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0be8b62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object'),\n",
       " Index(['model', 'train_dataset', 'eval_dataset', 'auc_mean', 'auc_std'], dtype='object')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.columns for k, df in dfs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a72b9f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pairwise', 'pooled', 'ft10', 'int10', 'ft2', 'int2', 'int20', 'int30', 'int40', 'int50'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4964902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY, FINETUNED, BASELINE, FT-SIZE, POOLED\n",
      "pairwise False False nan False\n",
      "pooled False False nan True\n",
      "ft10 True False 0.1 False\n",
      "int10 False True 0.1 False\n",
      "ft2 True False 0.02 False\n",
      "int2 False True 0.02 False\n",
      "int20 False True 0.2 False\n",
      "int30 False True 0.3 False\n",
      "int40 False True 0.4 False\n",
      "int50 False True 0.5 False\n"
     ]
    }
   ],
   "source": [
    "ft_size_mapping = {\n",
    "    'ft2': 0.02,\n",
    "    'ft10': 0.1,\n",
    "    'int2': 0.02,\n",
    "    'int10': 0.1,\n",
    "    'int20': 0.2,\n",
    "    'int30': 0.3,\n",
    "    'int40': 0.4,\n",
    "    'int50': 0.5,\n",
    "\n",
    "}\n",
    "print('KEY, FINETUNED, BASELINE, FT-SIZE, POOLED')\n",
    "for key, df in dfs.items():\n",
    "    is_finetuned = True if 'ft' in key else False\n",
    "    df['finetuned'] = is_finetuned\n",
    "    is_baseline = True if 'int' in key else False\n",
    "    df['baseline'] = is_baseline\n",
    "    is_pooled = True if 'pooled' in key else False\n",
    "    df['pooled'] = is_pooled\n",
    "    if key in ft_size_mapping.keys():\n",
    "        ft_size = ft_size_mapping[key]\n",
    "    else:\n",
    "        ft_size = np.nan\n",
    "    df['finetuning_size'] = ft_size\n",
    "   \n",
    "    print(key, is_finetuned, is_baseline, ft_size, is_pooled)\n",
    "    dfs[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8edc4344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRUModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.856065</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.893969</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.882309</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mews</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.718191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>mews</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.609735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>news</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.653109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>qsofa</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.566735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>sirs</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.608508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>sofa</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.693246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              model train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       "0    AttentionModel          aumc         aumc  0.916687  0.003649      False   \n",
       "1          GRUModel          aumc         aumc  0.856065  0.014158      False   \n",
       "2              lgbm          aumc         aumc  0.893969  0.004147      False   \n",
       "3                lr          aumc         aumc  0.882309  0.001821      False   \n",
       "4              mews          aumc         aumc  0.718191  0.000000      False   \n",
       "..              ...           ...          ...       ...       ...        ...   \n",
       "139            mews         mimic        mimic  0.609735  0.000000      False   \n",
       "140            news         mimic        mimic  0.653109  0.000000      False   \n",
       "141           qsofa         mimic        mimic  0.566735  0.000000      False   \n",
       "142            sirs         mimic        mimic  0.608508  0.000000      False   \n",
       "143            sofa         mimic        mimic  0.693246  0.000000      False   \n",
       "\n",
       "     baseline  finetuning_size  pooled  \n",
       "0       False              NaN   False  \n",
       "1       False              NaN   False  \n",
       "2       False              NaN   False  \n",
       "3       False              NaN   False  \n",
       "4       False              NaN   False  \n",
       "..        ...              ...     ...  \n",
       "139     False              NaN   False  \n",
       "140     False              NaN   False  \n",
       "141     False              NaN   False  \n",
       "142     False              NaN   False  \n",
       "143     False              NaN   False  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['pairwise']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4992cf",
   "metadata": {},
   "source": [
    "## load scatter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87aaa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfs = {key: pd.read_csv(val) for key,val in scatter_paths.items()} #scatter dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04877667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pairwise':       model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0    attn     4.200  0.266927  0.556745  0.022750          aumc         aumc\n",
       " 1    gru      4.195  0.778299  0.410201  0.043130          aumc         aumc\n",
       " 2    lgbm     6.530  0.816701  0.502154  0.018110          aumc         aumc\n",
       " 3    lr       6.125  0.390512  0.477825  0.007715          aumc         aumc\n",
       " 4    mews     5.000  0.000000  0.293807  0.000000          aumc         aumc\n",
       " ..      ...     ...       ...       ...       ...           ...          ...\n",
       " 139  mews     5.200  0.000000  0.226825  0.000000         mimic        mimic\n",
       " 140  news     4.025  0.000000  0.246847  0.000000         mimic        mimic\n",
       " 141  qsofa    4.250  0.000000  0.211539  0.000000         mimic        mimic\n",
       " 142  sirs     6.725  0.000000  0.223432  0.000000         mimic        mimic\n",
       " 143  sofa     0.000  0.000000  0.271080  0.000000         mimic        mimic\n",
       " \n",
       " [144 rows x 7 columns],\n",
       " 'pooled':      model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0   attn     0.980  0.967180  0.397105  0.027916        pooled         aumc\n",
       " 1   gru      1.430  0.933809  0.291874  0.024458        pooled         aumc\n",
       " 2   lgbm     0.390  0.650385  0.283941  0.014746        pooled         aumc\n",
       " 3   lr       5.995  0.956948  0.215510  0.009709        pooled         aumc\n",
       " 4   mews     5.000  0.000000  0.293807  0.000000        pooled         aumc\n",
       " 5   news     1.000  0.000000  0.311426  0.000000        pooled         aumc\n",
       " 6   qsofa    3.500  0.000000  0.275221  0.000000        pooled         aumc\n",
       " 7   sirs     5.750  0.000000  0.261571  0.000000        pooled         aumc\n",
       " 8   sofa     0.000  0.000000  0.225260  0.000000        pooled         aumc\n",
       " 9   attn     1.390  1.001499  0.310632  0.010381        pooled         eicu\n",
       " 10  gru      3.135  0.887342  0.299818  0.011820        pooled         eicu\n",
       " 11  lgbm     4.615  1.319517  0.268134  0.011079        pooled         eicu\n",
       " 12  lr       5.535  0.402958  0.285274  0.001646        pooled         eicu\n",
       " 13  mews    10.250  0.000000  0.220055  0.000000        pooled         eicu\n",
       " 14  news     9.250  0.000000  0.238544  0.000000        pooled         eicu\n",
       " 15  qsofa    8.000  0.000000  0.254275  0.000000        pooled         eicu\n",
       " 16  sirs     8.000  0.000000  0.269799  0.000000        pooled         eicu\n",
       " 17  sofa     3.750  0.000000  0.266581  0.000000        pooled         eicu\n",
       " 18  attn     1.165  1.106882  0.289927  0.011515        pooled        hirid\n",
       " 19  gru      1.180  0.576466  0.307897  0.006010        pooled        hirid\n",
       " 20  lgbm     1.160  0.619879  0.266530  0.011381        pooled        hirid\n",
       " 21  lr       7.650  0.215058  0.244500  0.016179        pooled        hirid\n",
       " 22  mews     6.850  0.000000  0.204811  0.000000        pooled        hirid\n",
       " 23  news     6.550  0.000000  0.247621  0.000000        pooled        hirid\n",
       " 24  qsofa    3.750  0.000000  0.206277  0.000000        pooled        hirid\n",
       " 25  sirs     6.600  0.000000  0.212086  0.000000        pooled        hirid\n",
       " 26  sofa     2.900  0.000000  0.309489  0.000000        pooled        hirid\n",
       " 27  attn     3.290  0.455041  0.274747  0.006186        pooled        mimic\n",
       " 28  gru      3.510  0.483671  0.273057  0.005707        pooled        mimic\n",
       " 29  lgbm     4.450  0.502183  0.241722  0.004378        pooled        mimic\n",
       " 30  lr       2.265  0.182517  0.273786  0.003512        pooled        mimic\n",
       " 31  mews     5.200  0.000000  0.226825  0.000000        pooled        mimic\n",
       " 32  news     4.025  0.000000  0.246847  0.000000        pooled        mimic\n",
       " 33  qsofa    4.250  0.000000  0.211539  0.000000        pooled        mimic\n",
       " 34  sirs     6.725  0.000000  0.223432  0.000000        pooled        mimic\n",
       " 35  sofa     0.000  0.000000  0.271080  0.000000        pooled        mimic,\n",
       " 'ft10':      model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0   attn     3.530  1.080856  0.308463  0.009794          aumc         eicu\n",
       " 1   attn     4.300  0.244949  0.341515  0.003953          aumc        hirid\n",
       " 2   attn     4.090  0.318983  0.318878  0.004958          aumc        mimic\n",
       " 3   attn     2.835  0.815015  0.476981  0.039907          eicu         aumc\n",
       " 4   attn     2.740  0.668160  0.319227  0.002441          eicu        hirid\n",
       " 5   attn     3.490  0.171026  0.330190  0.007292          eicu        mimic\n",
       " 6   attn     3.130  1.262735  0.435645  0.033262         hirid         aumc\n",
       " 7   attn     2.690  0.535490  0.312162  0.004907         hirid         eicu\n",
       " 8   attn     2.500  0.736758  0.331902  0.008562         hirid        mimic\n",
       " 9   attn     1.630  0.531037  0.517210  0.018889         mimic         aumc\n",
       " 10  attn     3.955  0.582130  0.347622  0.004144         mimic         eicu\n",
       " 11  attn     2.415  0.413673  0.329867  0.006922         mimic        hirid,\n",
       " 'int10':     model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0  attn     6.970  0.378071  0.427858  0.017469          aumc         aumc\n",
       " 1  attn     8.335  0.540717  0.279412  0.005725          eicu         eicu\n",
       " 2  attn     4.165  0.265518  0.328310  0.003261         hirid        hirid\n",
       " 3  attn     4.755  0.354612  0.318981  0.008402         mimic        mimic,\n",
       " 'ft2':      model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0   attn     5.555  0.649134  0.252831  0.003548          aumc         eicu\n",
       " 1   attn     6.220  0.566348  0.301949  0.005359          aumc        hirid\n",
       " 2   attn     3.645  1.332807  0.234105  0.015405          aumc        mimic\n",
       " 3   attn     3.195  1.059835  0.303952  0.071046          eicu         aumc\n",
       " 4   attn     1.910  0.806730  0.264214  0.006479          eicu        hirid\n",
       " 5   attn     3.915  0.277038  0.246401  0.009146          eicu        mimic\n",
       " 6   attn     2.175  0.653357  0.380352  0.021274         hirid         aumc\n",
       " 7   attn     4.690  1.025549  0.263921  0.008179         hirid         eicu\n",
       " 8   attn     1.555  1.337722  0.255292  0.008648         hirid        mimic\n",
       " 9   attn     2.865  1.803781  0.386290  0.037804         mimic         aumc\n",
       " 10  attn     5.125  0.257391  0.294014  0.004669         mimic         eicu\n",
       " 11  attn     1.245  0.366742  0.305844  0.004670         mimic        hirid,\n",
       " 'int2':     model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0  attn     8.575  0.729512  0.327786  0.011386          aumc         aumc\n",
       " 1  attn     8.350  0.385276  0.255480  0.005198          eicu         eicu\n",
       " 2  attn     5.455  0.156525  0.287224  0.003679         hirid        hirid\n",
       " 3  attn     5.305  0.207214  0.267340  0.003602         mimic        mimic,\n",
       " 'int20':     model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0  attn     5.925  0.558737  0.474521  0.021059          aumc         aumc\n",
       " 1  attn     5.820  0.378484  0.314440  0.004678          eicu         eicu\n",
       " 2  attn     2.730  0.442083  0.365034  0.005439         hirid        hirid\n",
       " 3  attn     4.855  0.473814  0.326511  0.011709         mimic        mimic,\n",
       " 'int30':     model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0  attn     4.965  0.593085  0.518494  0.016004          aumc         aumc\n",
       " 1  attn     5.425  0.556215  0.326966  0.010805          eicu         eicu\n",
       " 2  attn     2.845  0.345688  0.374574  0.004525         hirid        hirid\n",
       " 3  attn     4.585  0.373162  0.343703  0.010042         mimic        mimic,\n",
       " 'int40':     model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0  attn     5.365  0.569704  0.496189  0.026916          aumc         aumc\n",
       " 1  attn     3.715  0.738580  0.337931  0.005654          eicu         eicu\n",
       " 2  attn     2.985  0.450555  0.371422  0.006666         hirid        hirid\n",
       " 3  attn     3.995  0.306390  0.358798  0.005626         mimic        mimic,\n",
       " 'int50':     model  x_mean     x_std    y_mean     y_std train_dataset eval_dataset\n",
       " 0  attn     3.565  0.407584  0.545334  0.023250          aumc         aumc\n",
       " 1  attn     3.520  0.683374  0.348174  0.009799          eicu         eicu\n",
       " 2  attn     2.810  0.405663  0.377411  0.006312         hirid        hirid\n",
       " 3  attn     4.240  0.041833  0.361766  0.004234         mimic        mimic}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a83f8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to attn model:\n",
    "keys = ['pairwise', 'pooled']\n",
    "for key in keys:\n",
    "    dfs[key] = dfs[key].query(\"model == 'AttentionModel'\")\n",
    "    sdfs[key] = sdfs[key].query(\"model.str.contains('attn')\") #different versions of attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b0f7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "103da7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">pairwise</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.732736</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.683240</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int40</th>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.813339</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">int50</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793521</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.827356</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pairwise 0   AttentionModel          aumc         aumc  0.916687  0.003649   \n",
       "         9   AttentionModel          aumc         eicu  0.698914  0.010913   \n",
       "         18  AttentionModel          aumc        hirid  0.732736  0.013468   \n",
       "         27  AttentionModel          aumc        mimic  0.683240  0.013410   \n",
       "         36  AttentionModel          eicu         aumc  0.732401  0.006840   \n",
       "...                     ...           ...          ...       ...       ...   \n",
       "int40    3   AttentionModel         mimic        mimic  0.813339  0.001457   \n",
       "int50    0   AttentionModel          aumc         aumc  0.909833  0.004767   \n",
       "         1   AttentionModel          eicu         eicu  0.793521  0.003445   \n",
       "         2   AttentionModel         hirid        hirid  0.827356  0.001454   \n",
       "         3   AttentionModel         mimic        mimic  0.815000  0.001442   \n",
       "\n",
       "             finetuned  baseline  finetuning_size  pooled  \n",
       "pairwise 0       False     False              NaN   False  \n",
       "         9       False     False              NaN   False  \n",
       "         18      False     False              NaN   False  \n",
       "         27      False     False              NaN   False  \n",
       "         36      False     False              NaN   False  \n",
       "...                ...       ...              ...     ...  \n",
       "int40    3       False      True              0.4   False  \n",
       "int50    0       False      True              0.5   False  \n",
       "         1       False      True              0.5   False  \n",
       "         2       False      True              0.5   False  \n",
       "         3       False      True              0.5   False  \n",
       "\n",
       "[68 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff1874e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs = {}\n",
    "for k in dfs.keys():\n",
    "    full_dfs[k] = pd.merge(dfs[k], sdfs[k], on=['train_dataset', 'eval_dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b4c1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in full_dfs.keys():\n",
    "    full_dfs[k] = full_dfs[k].rename(columns=\n",
    "        {'x_mean': 'earliness_mean', \n",
    "         'x_std': 'earliness_std', \n",
    "         'y_mean': 'precision_mean', \n",
    "         'y_std': 'precision_std' }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91fb5ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pairwise':            model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0   AttentionModel          aumc         aumc  0.916687  0.003649      False   \n",
       " 1   AttentionModel          aumc         eicu  0.698914  0.010913      False   \n",
       " 2   AttentionModel          aumc        hirid  0.732736  0.013468      False   \n",
       " 3   AttentionModel          aumc        mimic  0.683240  0.013410      False   \n",
       " 4   AttentionModel          eicu         aumc  0.732401  0.006840      False   \n",
       " 5   AttentionModel          eicu         eicu  0.802011  0.003560      False   \n",
       " 6   AttentionModel          eicu        hirid  0.704782  0.026302      False   \n",
       " 7   AttentionModel          eicu        mimic  0.713040  0.009499      False   \n",
       " 8   AttentionModel         hirid         aumc  0.805040  0.014322      False   \n",
       " 9   AttentionModel         hirid         eicu  0.705298  0.009176      False   \n",
       " 10  AttentionModel         hirid        hirid  0.833421  0.002325      False   \n",
       " 11  AttentionModel         hirid        mimic  0.646188  0.013088      False   \n",
       " 12  AttentionModel         mimic         aumc  0.799113  0.023053      False   \n",
       " 13  AttentionModel         mimic         eicu  0.752309  0.007755      False   \n",
       " 14  AttentionModel         mimic        hirid  0.693788  0.010552      False   \n",
       " 15  AttentionModel         mimic        mimic  0.830490  0.003029      False   \n",
       " \n",
       "     baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      False              NaN   False  attn             4.200       0.266927   \n",
       " 1      False              NaN   False  attn             3.665       1.215730   \n",
       " 2      False              NaN   False  attn             3.120       1.037184   \n",
       " 3      False              NaN   False  attn             4.065       1.208770   \n",
       " 4      False              NaN   False  attn             3.620       1.381055   \n",
       " 5      False              NaN   False  attn             4.615       0.986724   \n",
       " 6      False              NaN   False  attn             2.595       1.117111   \n",
       " 7      False              NaN   False  attn             4.055       0.391871   \n",
       " 8      False              NaN   False  attn             1.430       0.642845   \n",
       " 9      False              NaN   False  attn             2.935       0.848454   \n",
       " 10     False              NaN   False  attn             2.730       0.220369   \n",
       " 11     False              NaN   False  attn             3.060       1.015905   \n",
       " 12     False              NaN   False  attn             3.050       2.042134   \n",
       " 13     False              NaN   False  attn             3.565       0.950592   \n",
       " 14     False              NaN   False  attn             0.845       0.834865   \n",
       " 15     False              NaN   False  attn             3.325       0.340955   \n",
       " \n",
       "     precision_mean  precision_std  \n",
       " 0         0.556745       0.022750  \n",
       " 1         0.270020       0.008207  \n",
       " 2         0.296823       0.012759  \n",
       " 3         0.250691       0.008047  \n",
       " 4         0.275125       0.008972  \n",
       " 5         0.347525       0.010727  \n",
       " 6         0.275680       0.019701  \n",
       " 7         0.265549       0.006703  \n",
       " 8         0.350750       0.035958  \n",
       " 9         0.265624       0.008938  \n",
       " 10        0.392262       0.007573  \n",
       " 11        0.225473       0.008254  \n",
       " 12        0.341887       0.050935  \n",
       " 13        0.308091       0.010487  \n",
       " 14        0.261874       0.012088  \n",
       " 15        0.381639       0.007537  ,\n",
       " 'pooled':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel        pooled         aumc  0.836354  0.010690      False   \n",
       " 1  AttentionModel        pooled         eicu  0.759689  0.006701      False   \n",
       " 2  AttentionModel        pooled        hirid  0.728090  0.013592      False   \n",
       " 3  AttentionModel        pooled        mimic  0.719022  0.005418      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0     False              NaN    True  attn             0.980       0.967180   \n",
       " 1     False              NaN    True  attn             1.390       1.001499   \n",
       " 2     False              NaN    True  attn             1.165       1.106882   \n",
       " 3     False              NaN    True  attn             3.290       0.455041   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.397105       0.027916  \n",
       " 1        0.310632       0.010381  \n",
       " 2        0.289927       0.011515  \n",
       " 3        0.274747       0.006186  ,\n",
       " 'ft10':            model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0   AttentionModel          aumc         eicu  0.756380  0.007044       True   \n",
       " 1   AttentionModel          aumc        hirid  0.791977  0.002111       True   \n",
       " 2   AttentionModel          aumc        mimic  0.784582  0.001923       True   \n",
       " 3   AttentionModel          eicu         aumc  0.873557  0.016987       True   \n",
       " 4   AttentionModel          eicu        hirid  0.773977  0.001597       True   \n",
       " 5   AttentionModel          eicu        mimic  0.788518  0.002695       True   \n",
       " 6   AttentionModel         hirid         aumc  0.866544  0.010388       True   \n",
       " 7   AttentionModel         hirid         eicu  0.761616  0.004486       True   \n",
       " 8   AttentionModel         hirid        mimic  0.793447  0.002462       True   \n",
       " 9   AttentionModel         mimic         aumc  0.893961  0.003589       True   \n",
       " 10  AttentionModel         mimic         eicu  0.792816  0.003978       True   \n",
       " 11  AttentionModel         mimic        hirid  0.796193  0.003922       True   \n",
       " \n",
       "     baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      False              0.1   False  attn             3.530       1.080856   \n",
       " 1      False              0.1   False  attn             4.300       0.244949   \n",
       " 2      False              0.1   False  attn             4.090       0.318983   \n",
       " 3      False              0.1   False  attn             2.835       0.815015   \n",
       " 4      False              0.1   False  attn             2.740       0.668160   \n",
       " 5      False              0.1   False  attn             3.490       0.171026   \n",
       " 6      False              0.1   False  attn             3.130       1.262735   \n",
       " 7      False              0.1   False  attn             2.690       0.535490   \n",
       " 8      False              0.1   False  attn             2.500       0.736758   \n",
       " 9      False              0.1   False  attn             1.630       0.531037   \n",
       " 10     False              0.1   False  attn             3.955       0.582130   \n",
       " 11     False              0.1   False  attn             2.415       0.413673   \n",
       " \n",
       "     precision_mean  precision_std  \n",
       " 0         0.308463       0.009794  \n",
       " 1         0.341515       0.003953  \n",
       " 2         0.318878       0.004958  \n",
       " 3         0.476981       0.039907  \n",
       " 4         0.319227       0.002441  \n",
       " 5         0.330190       0.007292  \n",
       " 6         0.435645       0.033262  \n",
       " 7         0.312162       0.004907  \n",
       " 8         0.331902       0.008562  \n",
       " 9         0.517210       0.018889  \n",
       " 10        0.347622       0.004144  \n",
       " 11        0.329867       0.006922  ,\n",
       " 'int10':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel          aumc         aumc  0.828403  0.004555      False   \n",
       " 1  AttentionModel          eicu         eicu  0.728809  0.005498      False   \n",
       " 2  AttentionModel         hirid        hirid  0.786867  0.001333      False   \n",
       " 3  AttentionModel         mimic        mimic  0.780787  0.002129      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      True              0.1   False  attn             6.970       0.378071   \n",
       " 1      True              0.1   False  attn             8.335       0.540717   \n",
       " 2      True              0.1   False  attn             4.165       0.265518   \n",
       " 3      True              0.1   False  attn             4.755       0.354612   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.427858       0.017469  \n",
       " 1        0.279412       0.005725  \n",
       " 2        0.328310       0.003261  \n",
       " 3        0.318981       0.008402  ,\n",
       " 'ft2':            model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0   AttentionModel          aumc         eicu  0.724866  0.003635       True   \n",
       " 1   AttentionModel          aumc        hirid  0.774966  0.002813       True   \n",
       " 2   AttentionModel          aumc        mimic  0.699866  0.023450       True   \n",
       " 3   AttentionModel          eicu         aumc  0.773791  0.041005       True   \n",
       " 4   AttentionModel          eicu        hirid  0.729016  0.010541       True   \n",
       " 5   AttentionModel          eicu        mimic  0.724120  0.011153       True   \n",
       " 6   AttentionModel         hirid         aumc  0.844473  0.011185       True   \n",
       " 7   AttentionModel         hirid         eicu  0.742710  0.006265       True   \n",
       " 8   AttentionModel         hirid        mimic  0.737982  0.009524       True   \n",
       " 9   AttentionModel         mimic         aumc  0.843931  0.013971       True   \n",
       " 10  AttentionModel         mimic         eicu  0.780288  0.002248       True   \n",
       " 11  AttentionModel         mimic        hirid  0.782912  0.003641       True   \n",
       " \n",
       "     baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      False             0.02   False  attn             5.555       0.649134   \n",
       " 1      False             0.02   False  attn             6.220       0.566348   \n",
       " 2      False             0.02   False  attn             3.645       1.332807   \n",
       " 3      False             0.02   False  attn             3.195       1.059835   \n",
       " 4      False             0.02   False  attn             1.910       0.806730   \n",
       " 5      False             0.02   False  attn             3.915       0.277038   \n",
       " 6      False             0.02   False  attn             2.175       0.653357   \n",
       " 7      False             0.02   False  attn             4.690       1.025549   \n",
       " 8      False             0.02   False  attn             1.555       1.337722   \n",
       " 9      False             0.02   False  attn             2.865       1.803781   \n",
       " 10     False             0.02   False  attn             5.125       0.257391   \n",
       " 11     False             0.02   False  attn             1.245       0.366742   \n",
       " \n",
       "     precision_mean  precision_std  \n",
       " 0         0.252831       0.003548  \n",
       " 1         0.301949       0.005359  \n",
       " 2         0.234105       0.015405  \n",
       " 3         0.303952       0.071046  \n",
       " 4         0.264214       0.006479  \n",
       " 5         0.246401       0.009146  \n",
       " 6         0.380352       0.021274  \n",
       " 7         0.263921       0.008179  \n",
       " 8         0.255292       0.008648  \n",
       " 9         0.386290       0.037804  \n",
       " 10        0.294014       0.004669  \n",
       " 11        0.305844       0.004670  ,\n",
       " 'int2':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel          aumc         aumc  0.807556  0.006384      False   \n",
       " 1  AttentionModel          eicu         eicu  0.711287  0.003618      False   \n",
       " 2  AttentionModel         hirid        hirid  0.763304  0.001136      False   \n",
       " 3  AttentionModel         mimic        mimic  0.745647  0.002570      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      True             0.02   False  attn             8.575       0.729512   \n",
       " 1      True             0.02   False  attn             8.350       0.385276   \n",
       " 2      True             0.02   False  attn             5.455       0.156525   \n",
       " 3      True             0.02   False  attn             5.305       0.207214   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.327786       0.011386  \n",
       " 1        0.255480       0.005198  \n",
       " 2        0.287224       0.003679  \n",
       " 3        0.267340       0.003602  ,\n",
       " 'int20':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel          aumc         aumc  0.877893  0.005566      False   \n",
       " 1  AttentionModel          eicu         eicu  0.770960  0.001698      False   \n",
       " 2  AttentionModel         hirid        hirid  0.807189  0.002594      False   \n",
       " 3  AttentionModel         mimic        mimic  0.795053  0.003343      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      True              0.2   False  attn             5.925       0.558737   \n",
       " 1      True              0.2   False  attn             5.820       0.378484   \n",
       " 2      True              0.2   False  attn             2.730       0.442083   \n",
       " 3      True              0.2   False  attn             4.855       0.473814   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.474521       0.021059  \n",
       " 1        0.314440       0.004678  \n",
       " 2        0.365034       0.005439  \n",
       " 3        0.326511       0.011709  ,\n",
       " 'int30':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel          aumc         aumc  0.902545  0.006045      False   \n",
       " 1  AttentionModel          eicu         eicu  0.781635  0.003264      False   \n",
       " 2  AttentionModel         hirid        hirid  0.818751  0.001395      False   \n",
       " 3  AttentionModel         mimic        mimic  0.800797  0.002360      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      True              0.3   False  attn             4.965       0.593085   \n",
       " 1      True              0.3   False  attn             5.425       0.556215   \n",
       " 2      True              0.3   False  attn             2.845       0.345688   \n",
       " 3      True              0.3   False  attn             4.585       0.373162   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.518494       0.016004  \n",
       " 1        0.326966       0.010805  \n",
       " 2        0.374574       0.004525  \n",
       " 3        0.343703       0.010042  ,\n",
       " 'int40':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel          aumc         aumc  0.905926  0.007608      False   \n",
       " 1  AttentionModel          eicu         eicu  0.792517  0.003944      False   \n",
       " 2  AttentionModel         hirid        hirid  0.818480  0.001562      False   \n",
       " 3  AttentionModel         mimic        mimic  0.813339  0.001457      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      True              0.4   False  attn             5.365       0.569704   \n",
       " 1      True              0.4   False  attn             3.715       0.738580   \n",
       " 2      True              0.4   False  attn             2.985       0.450555   \n",
       " 3      True              0.4   False  attn             3.995       0.306390   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.496189       0.026916  \n",
       " 1        0.337931       0.005654  \n",
       " 2        0.371422       0.006666  \n",
       " 3        0.358798       0.005626  ,\n",
       " 'int50':           model_x train_dataset eval_dataset  auc_mean   auc_std  finetuned  \\\n",
       " 0  AttentionModel          aumc         aumc  0.909833  0.004767      False   \n",
       " 1  AttentionModel          eicu         eicu  0.793521  0.003445      False   \n",
       " 2  AttentionModel         hirid        hirid  0.827356  0.001454      False   \n",
       " 3  AttentionModel         mimic        mimic  0.815000  0.001442      False   \n",
       " \n",
       "    baseline  finetuning_size  pooled model_y  earliness_mean  earliness_std  \\\n",
       " 0      True              0.5   False  attn             3.565       0.407584   \n",
       " 1      True              0.5   False  attn             3.520       0.683374   \n",
       " 2      True              0.5   False  attn             2.810       0.405663   \n",
       " 3      True              0.5   False  attn             4.240       0.041833   \n",
       " \n",
       "    precision_mean  precision_std  \n",
       " 0        0.545334       0.023250  \n",
       " 1        0.348174       0.009799  \n",
       " 2        0.377411       0.006312  \n",
       " 3        0.361766       0.004234  }"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6859772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(full_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c288433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AttentionModel'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0549221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">pairwise</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.200</td>\n",
       "      <td>0.266927</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.665</td>\n",
       "      <td>1.215730</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.732736</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.120</td>\n",
       "      <td>1.037184</td>\n",
       "      <td>0.296823</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.683240</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.065</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.250691</td>\n",
       "      <td>0.008047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.620</td>\n",
       "      <td>1.381055</td>\n",
       "      <td>0.275125</td>\n",
       "      <td>0.008972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int40</th>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.813339</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.995</td>\n",
       "      <td>0.306390</td>\n",
       "      <td>0.358798</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">int50</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.565</td>\n",
       "      <td>0.407584</td>\n",
       "      <td>0.545334</td>\n",
       "      <td>0.023250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793521</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.520</td>\n",
       "      <td>0.683374</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.009799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.827356</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.810</td>\n",
       "      <td>0.405663</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>0.006312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.240</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.361766</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pairwise 0  AttentionModel          aumc         aumc  0.916687  0.003649   \n",
       "         1  AttentionModel          aumc         eicu  0.698914  0.010913   \n",
       "         2  AttentionModel          aumc        hirid  0.732736  0.013468   \n",
       "         3  AttentionModel          aumc        mimic  0.683240  0.013410   \n",
       "         4  AttentionModel          eicu         aumc  0.732401  0.006840   \n",
       "...                    ...           ...          ...       ...       ...   \n",
       "int40    3  AttentionModel         mimic        mimic  0.813339  0.001457   \n",
       "int50    0  AttentionModel          aumc         aumc  0.909833  0.004767   \n",
       "         1  AttentionModel          eicu         eicu  0.793521  0.003445   \n",
       "         2  AttentionModel         hirid        hirid  0.827356  0.001454   \n",
       "         3  AttentionModel         mimic        mimic  0.815000  0.001442   \n",
       "\n",
       "            finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "pairwise 0      False     False              NaN   False  attn     \n",
       "         1      False     False              NaN   False  attn     \n",
       "         2      False     False              NaN   False  attn     \n",
       "         3      False     False              NaN   False  attn     \n",
       "         4      False     False              NaN   False  attn     \n",
       "...               ...       ...              ...     ...     ...   \n",
       "int40    3      False      True              0.4   False  attn     \n",
       "int50    0      False      True              0.5   False  attn     \n",
       "         1      False      True              0.5   False  attn     \n",
       "         2      False      True              0.5   False  attn     \n",
       "         3      False      True              0.5   False  attn     \n",
       "\n",
       "            earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "pairwise 0           4.200       0.266927        0.556745       0.022750  \n",
       "         1           3.665       1.215730        0.270020       0.008207  \n",
       "         2           3.120       1.037184        0.296823       0.012759  \n",
       "         3           4.065       1.208770        0.250691       0.008047  \n",
       "         4           3.620       1.381055        0.275125       0.008972  \n",
       "...                    ...            ...             ...            ...  \n",
       "int40    3           3.995       0.306390        0.358798       0.005626  \n",
       "int50    0           3.565       0.407584        0.545334       0.023250  \n",
       "         1           3.520       0.683374        0.348174       0.009799  \n",
       "         2           2.810       0.405663        0.377411       0.006312  \n",
       "         3           4.240       0.041833        0.361766       0.004234  \n",
       "\n",
       "[68 rows x 14 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68914967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we look at the attn model:\n",
    "df = df.query(\"model_x == 'AttentionModel'\")\n",
    "# drop obsolete dataset (too heterogenous / low quality)\n",
    "df = df.query(\"train_dataset != 'emory' & eval_dataset != 'emory'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1de4b861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">pairwise</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.200</td>\n",
       "      <td>0.266927</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.665</td>\n",
       "      <td>1.215730</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.732736</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.120</td>\n",
       "      <td>1.037184</td>\n",
       "      <td>0.296823</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.683240</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.065</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.250691</td>\n",
       "      <td>0.008047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.620</td>\n",
       "      <td>1.381055</td>\n",
       "      <td>0.275125</td>\n",
       "      <td>0.008972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int40</th>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.813339</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.995</td>\n",
       "      <td>0.306390</td>\n",
       "      <td>0.358798</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">int50</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.565</td>\n",
       "      <td>0.407584</td>\n",
       "      <td>0.545334</td>\n",
       "      <td>0.023250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793521</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.520</td>\n",
       "      <td>0.683374</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.009799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.827356</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.810</td>\n",
       "      <td>0.405663</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>0.006312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.240</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.361766</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pairwise 0  AttentionModel          aumc         aumc  0.916687  0.003649   \n",
       "         1  AttentionModel          aumc         eicu  0.698914  0.010913   \n",
       "         2  AttentionModel          aumc        hirid  0.732736  0.013468   \n",
       "         3  AttentionModel          aumc        mimic  0.683240  0.013410   \n",
       "         4  AttentionModel          eicu         aumc  0.732401  0.006840   \n",
       "...                    ...           ...          ...       ...       ...   \n",
       "int40    3  AttentionModel         mimic        mimic  0.813339  0.001457   \n",
       "int50    0  AttentionModel          aumc         aumc  0.909833  0.004767   \n",
       "         1  AttentionModel          eicu         eicu  0.793521  0.003445   \n",
       "         2  AttentionModel         hirid        hirid  0.827356  0.001454   \n",
       "         3  AttentionModel         mimic        mimic  0.815000  0.001442   \n",
       "\n",
       "            finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "pairwise 0      False     False              NaN   False  attn     \n",
       "         1      False     False              NaN   False  attn     \n",
       "         2      False     False              NaN   False  attn     \n",
       "         3      False     False              NaN   False  attn     \n",
       "         4      False     False              NaN   False  attn     \n",
       "...               ...       ...              ...     ...     ...   \n",
       "int40    3      False      True              0.4   False  attn     \n",
       "int50    0      False      True              0.5   False  attn     \n",
       "         1      False      True              0.5   False  attn     \n",
       "         2      False      True              0.5   False  attn     \n",
       "         3      False      True              0.5   False  attn     \n",
       "\n",
       "            earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "pairwise 0           4.200       0.266927        0.556745       0.022750  \n",
       "         1           3.665       1.215730        0.270020       0.008207  \n",
       "         2           3.120       1.037184        0.296823       0.012759  \n",
       "         3           4.065       1.208770        0.250691       0.008047  \n",
       "         4           3.620       1.381055        0.275125       0.008972  \n",
       "...                    ...            ...             ...            ...  \n",
       "int40    3           3.995       0.306390        0.358798       0.005626  \n",
       "int50    0           3.565       0.407584        0.545334       0.023250  \n",
       "         1           3.520       0.683374        0.348174       0.009799  \n",
       "         2           2.810       0.405663        0.377411       0.006312  \n",
       "         3           4.240       0.041833        0.361766       0.004234  \n",
       "\n",
       "[68 rows x 14 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05b5ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df.query(\"train_dataset == eval_dataset & \\\n",
    "        finetuned == False & \\\n",
    "        train_dataset != 'pooled' & \\\n",
    "        baseline == False\"\n",
    ")\n",
    "assert len(df_int) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80e1eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pairwise</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.200</td>\n",
       "      <td>0.266927</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.802011</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.615</td>\n",
       "      <td>0.986724</td>\n",
       "      <td>0.347525</td>\n",
       "      <td>0.010727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.833421</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.730</td>\n",
       "      <td>0.220369</td>\n",
       "      <td>0.392262</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.830490</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.325</td>\n",
       "      <td>0.340955</td>\n",
       "      <td>0.381639</td>\n",
       "      <td>0.007537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pairwise 0   AttentionModel          aumc         aumc  0.916687  0.003649   \n",
       "         5   AttentionModel          eicu         eicu  0.802011  0.003560   \n",
       "         10  AttentionModel         hirid        hirid  0.833421  0.002325   \n",
       "         15  AttentionModel         mimic        mimic  0.830490  0.003029   \n",
       "\n",
       "             finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "pairwise 0       False     False              NaN   False  attn     \n",
       "         5       False     False              NaN   False  attn     \n",
       "         10      False     False              NaN   False  attn     \n",
       "         15      False     False              NaN   False  attn     \n",
       "\n",
       "             earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "pairwise 0            4.200       0.266927        0.556745       0.022750  \n",
       "         5            4.615       0.986724        0.347525       0.010727  \n",
       "         10           2.730       0.220369        0.392262       0.007573  \n",
       "         15           3.325       0.340955        0.381639       0.007537  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8e22a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliness_means = {}\n",
    "earliness_stds = {}\n",
    "precision_means = {}\n",
    "precision_stds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f204498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1228713345.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int'] = df_int.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1228713345.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int'] = df_int.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int'] = df_int.mean()['earliness_mean']\n",
    "earliness_stds['int'] = df_int.std()['earliness_mean']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d7d333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pw = df.query(\"train_dataset != eval_dataset & finetuned == False & train_dataset != 'pooled' & baseline == False\")\n",
    "assert len(df_pw) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47db0eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">pairwise</th>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.665</td>\n",
       "      <td>1.215730</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.732736</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.120</td>\n",
       "      <td>1.037184</td>\n",
       "      <td>0.296823</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.683240</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.065</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.250691</td>\n",
       "      <td>0.008047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.620</td>\n",
       "      <td>1.381055</td>\n",
       "      <td>0.275125</td>\n",
       "      <td>0.008972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.704782</td>\n",
       "      <td>0.026302</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.595</td>\n",
       "      <td>1.117111</td>\n",
       "      <td>0.275680</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.713040</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.055</td>\n",
       "      <td>0.391871</td>\n",
       "      <td>0.265549</td>\n",
       "      <td>0.006703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.805040</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.430</td>\n",
       "      <td>0.642845</td>\n",
       "      <td>0.350750</td>\n",
       "      <td>0.035958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.705298</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.935</td>\n",
       "      <td>0.848454</td>\n",
       "      <td>0.265624</td>\n",
       "      <td>0.008938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.646188</td>\n",
       "      <td>0.013088</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.060</td>\n",
       "      <td>1.015905</td>\n",
       "      <td>0.225473</td>\n",
       "      <td>0.008254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.799113</td>\n",
       "      <td>0.023053</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.050</td>\n",
       "      <td>2.042134</td>\n",
       "      <td>0.341887</td>\n",
       "      <td>0.050935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.752309</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.565</td>\n",
       "      <td>0.950592</td>\n",
       "      <td>0.308091</td>\n",
       "      <td>0.010487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.693788</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.834865</td>\n",
       "      <td>0.261874</td>\n",
       "      <td>0.012088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pairwise 1   AttentionModel          aumc         eicu  0.698914  0.010913   \n",
       "         2   AttentionModel          aumc        hirid  0.732736  0.013468   \n",
       "         3   AttentionModel          aumc        mimic  0.683240  0.013410   \n",
       "         4   AttentionModel          eicu         aumc  0.732401  0.006840   \n",
       "         6   AttentionModel          eicu        hirid  0.704782  0.026302   \n",
       "         7   AttentionModel          eicu        mimic  0.713040  0.009499   \n",
       "         8   AttentionModel         hirid         aumc  0.805040  0.014322   \n",
       "         9   AttentionModel         hirid         eicu  0.705298  0.009176   \n",
       "         11  AttentionModel         hirid        mimic  0.646188  0.013088   \n",
       "         12  AttentionModel         mimic         aumc  0.799113  0.023053   \n",
       "         13  AttentionModel         mimic         eicu  0.752309  0.007755   \n",
       "         14  AttentionModel         mimic        hirid  0.693788  0.010552   \n",
       "\n",
       "             finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "pairwise 1       False     False              NaN   False  attn     \n",
       "         2       False     False              NaN   False  attn     \n",
       "         3       False     False              NaN   False  attn     \n",
       "         4       False     False              NaN   False  attn     \n",
       "         6       False     False              NaN   False  attn     \n",
       "         7       False     False              NaN   False  attn     \n",
       "         8       False     False              NaN   False  attn     \n",
       "         9       False     False              NaN   False  attn     \n",
       "         11      False     False              NaN   False  attn     \n",
       "         12      False     False              NaN   False  attn     \n",
       "         13      False     False              NaN   False  attn     \n",
       "         14      False     False              NaN   False  attn     \n",
       "\n",
       "             earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "pairwise 1            3.665       1.215730        0.270020       0.008207  \n",
       "         2            3.120       1.037184        0.296823       0.012759  \n",
       "         3            4.065       1.208770        0.250691       0.008047  \n",
       "         4            3.620       1.381055        0.275125       0.008972  \n",
       "         6            2.595       1.117111        0.275680       0.019701  \n",
       "         7            4.055       0.391871        0.265549       0.006703  \n",
       "         8            1.430       0.642845        0.350750       0.035958  \n",
       "         9            2.935       0.848454        0.265624       0.008938  \n",
       "         11           3.060       1.015905        0.225473       0.008254  \n",
       "         12           3.050       2.042134        0.341887       0.050935  \n",
       "         13           3.565       0.950592        0.308091       0.010487  \n",
       "         14           0.845       0.834865        0.261874       0.012088  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "492f1303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1354249333.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['pw'] = df_pw.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1354249333.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['pw'] = df_pw.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['pw'] = df_pw.mean()['earliness_mean']\n",
    "earliness_stds['pw'] = df_pw.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39ed4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.7175000000000002, 'pw': 3.0004166666666663}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "090135a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_po = df.query(\"train_dataset == 'pooled' & finetuned == False & baseline == False\")\n",
    "assert len(df_po) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e476a7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pooled</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.836354</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.967180</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.027916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.759689</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.390</td>\n",
       "      <td>1.001499</td>\n",
       "      <td>0.310632</td>\n",
       "      <td>0.010381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.728090</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1.106882</td>\n",
       "      <td>0.289927</td>\n",
       "      <td>0.011515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.719022</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.290</td>\n",
       "      <td>0.455041</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pooled 0  AttentionModel        pooled         aumc  0.836354  0.010690   \n",
       "       1  AttentionModel        pooled         eicu  0.759689  0.006701   \n",
       "       2  AttentionModel        pooled        hirid  0.728090  0.013592   \n",
       "       3  AttentionModel        pooled        mimic  0.719022  0.005418   \n",
       "\n",
       "          finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "pooled 0      False     False              NaN    True  attn     \n",
       "       1      False     False              NaN    True  attn     \n",
       "       2      False     False              NaN    True  attn     \n",
       "       3      False     False              NaN    True  attn     \n",
       "\n",
       "          earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "pooled 0           0.980       0.967180        0.397105       0.027916  \n",
       "       1           1.390       1.001499        0.310632       0.010381  \n",
       "       2           1.165       1.106882        0.289927       0.011515  \n",
       "       3           3.290       0.455041        0.274747       0.006186  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37cc4a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/4184905722.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['po'] = df_po.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/4184905722.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['po'] = df_po.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['po'] = df_po.mean()['earliness_mean']\n",
    "earliness_stds['po'] = df_po.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0364e84",
   "metadata": {},
   "source": [
    "## finetuning on 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac8cd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft(ft_size=0.10):\n",
    "    return df.query(\"train_dataset != 'pooled' & finetuned == True & baseline == False & finetuning_size == @ft_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d39fc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft10 = get_ft(0.10)\n",
    "#auc_ft10_mean = df_ft10['auc_mean'].mean()\n",
    "#auc_ft10_std = df_ft10['auc_mean'].std()\n",
    "assert len(df_ft10) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "116ff452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">ft10</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.756380</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.530</td>\n",
       "      <td>1.080856</td>\n",
       "      <td>0.308463</td>\n",
       "      <td>0.009794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.791977</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.300</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.341515</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.784582</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.090</td>\n",
       "      <td>0.318983</td>\n",
       "      <td>0.318878</td>\n",
       "      <td>0.004958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.835</td>\n",
       "      <td>0.815015</td>\n",
       "      <td>0.476981</td>\n",
       "      <td>0.039907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.773977</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.740</td>\n",
       "      <td>0.668160</td>\n",
       "      <td>0.319227</td>\n",
       "      <td>0.002441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.788518</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.490</td>\n",
       "      <td>0.171026</td>\n",
       "      <td>0.330190</td>\n",
       "      <td>0.007292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.866544</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.130</td>\n",
       "      <td>1.262735</td>\n",
       "      <td>0.435645</td>\n",
       "      <td>0.033262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.690</td>\n",
       "      <td>0.535490</td>\n",
       "      <td>0.312162</td>\n",
       "      <td>0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.793447</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.736758</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.008562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.893961</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.630</td>\n",
       "      <td>0.531037</td>\n",
       "      <td>0.517210</td>\n",
       "      <td>0.018889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.792816</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.955</td>\n",
       "      <td>0.582130</td>\n",
       "      <td>0.347622</td>\n",
       "      <td>0.004144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.796193</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.415</td>\n",
       "      <td>0.413673</td>\n",
       "      <td>0.329867</td>\n",
       "      <td>0.006922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "ft10 0   AttentionModel          aumc         eicu  0.756380  0.007044   \n",
       "     1   AttentionModel          aumc        hirid  0.791977  0.002111   \n",
       "     2   AttentionModel          aumc        mimic  0.784582  0.001923   \n",
       "     3   AttentionModel          eicu         aumc  0.873557  0.016987   \n",
       "     4   AttentionModel          eicu        hirid  0.773977  0.001597   \n",
       "     5   AttentionModel          eicu        mimic  0.788518  0.002695   \n",
       "     6   AttentionModel         hirid         aumc  0.866544  0.010388   \n",
       "     7   AttentionModel         hirid         eicu  0.761616  0.004486   \n",
       "     8   AttentionModel         hirid        mimic  0.793447  0.002462   \n",
       "     9   AttentionModel         mimic         aumc  0.893961  0.003589   \n",
       "     10  AttentionModel         mimic         eicu  0.792816  0.003978   \n",
       "     11  AttentionModel         mimic        hirid  0.796193  0.003922   \n",
       "\n",
       "         finetuned  baseline  finetuning_size  pooled model_y  earliness_mean  \\\n",
       "ft10 0        True     False              0.1   False  attn             3.530   \n",
       "     1        True     False              0.1   False  attn             4.300   \n",
       "     2        True     False              0.1   False  attn             4.090   \n",
       "     3        True     False              0.1   False  attn             2.835   \n",
       "     4        True     False              0.1   False  attn             2.740   \n",
       "     5        True     False              0.1   False  attn             3.490   \n",
       "     6        True     False              0.1   False  attn             3.130   \n",
       "     7        True     False              0.1   False  attn             2.690   \n",
       "     8        True     False              0.1   False  attn             2.500   \n",
       "     9        True     False              0.1   False  attn             1.630   \n",
       "     10       True     False              0.1   False  attn             3.955   \n",
       "     11       True     False              0.1   False  attn             2.415   \n",
       "\n",
       "         earliness_std  precision_mean  precision_std  \n",
       "ft10 0        1.080856        0.308463       0.009794  \n",
       "     1        0.244949        0.341515       0.003953  \n",
       "     2        0.318983        0.318878       0.004958  \n",
       "     3        0.815015        0.476981       0.039907  \n",
       "     4        0.668160        0.319227       0.002441  \n",
       "     5        0.171026        0.330190       0.007292  \n",
       "     6        1.262735        0.435645       0.033262  \n",
       "     7        0.535490        0.312162       0.004907  \n",
       "     8        0.736758        0.331902       0.008562  \n",
       "     9        0.531037        0.517210       0.018889  \n",
       "     10       0.582130        0.347622       0.004144  \n",
       "     11       0.413673        0.329867       0.006922  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7ee5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/894474592.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['ft10'] = df_ft10.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/894474592.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['ft10'] = df_ft10.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['ft10'] = df_ft10.mean()['earliness_mean']\n",
    "earliness_stds['ft10'] = df_ft10.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d9c98ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375,\n",
       " 'pw': 3.0066666666666664,\n",
       " 'po': 1.7537500000000001,\n",
       " 'ft10': 3.116666666666667}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5aac505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(ft_size=0.10):\n",
    "    return df.query(\"train_dataset != 'pooled' & finetuned == False & baseline == True & finetuning_size == @ft_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85318a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base10 = get_baseline(0.10)\n",
    "#auc_base10_mean = df_base10['auc_mean'].mean()\n",
    "#auc_base10_std = df_base10['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0cbfcc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1832192828.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int10'] = df_base10.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1832192828.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int10'] = df_base10.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int10'] = df_base10.mean()['earliness_mean']\n",
    "earliness_stds['int10'] = df_base10.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3d34e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 0.8500049019466496,\n",
       " 'pw': 0.9858440277090981,\n",
       " 'po': 1.0690601401854496,\n",
       " 'ft10': 0.7889092729262923,\n",
       " 'int10': 1.9405943032998934}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_stds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5793918",
   "metadata": {},
   "source": [
    "## finetuning on 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "da1f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft2 = get_ft(0.02)\n",
    "#auc_ft2_mean = df_ft2['auc_mean'].mean()\n",
    "#auc_ft2_std = df_ft2['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b502d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/2657514013.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['ft2'] = df_ft2.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/2657514013.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['ft2'] = df_ft2.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['ft2'] = df_ft2.mean()['earliness_mean']\n",
    "earliness_stds['ft2'] = df_ft2.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a9647c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.7175000000000002,\n",
       " 'pw': 3.0004166666666663,\n",
       " 'po': 1.70625,\n",
       " 'ft10': 3.10875,\n",
       " 'int10': 6.0562499999999995,\n",
       " 'ft2': 3.507916666666667}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a04c0d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7632434823574795"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#auc_ft2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f8408b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2 = get_baseline(0.02)\n",
    "#auc_base2_mean = df_base2['auc_mean'].mean()\n",
    "#auc_base2_std = df_base2['auc_mean'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4c15a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1515663671.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int2'] = df_base2.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1515663671.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int2'] = df_base2.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int2'] = df_base2.mean()['earliness_mean']\n",
    "earliness_stds['int2'] = df_base2.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86242c5c",
   "metadata": {},
   "source": [
    "## Baseline on 20% (internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b70d93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base20 = get_baseline(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0ce2b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1005798550.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int20'] = df_base20.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1005798550.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int20'] = df_base20.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "earliness_means['int20'] = df_base20.mean()['earliness_mean']\n",
    "earliness_stds['int20'] = df_base20.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39daf10",
   "metadata": {},
   "source": [
    "## Baseline on 30% (internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "177a7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/4292486324.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int30'] = df_base30.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/4292486324.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int30'] = df_base30.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "df_base30 = get_baseline(0.3)\n",
    "earliness_means['int30'] = df_base30.mean()['earliness_mean']\n",
    "earliness_stds['int30'] = df_base30.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f104e",
   "metadata": {},
   "source": [
    "## Baseline on 40% (internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3958e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/29571973.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int40'] = df_base40.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/29571973.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int40'] = df_base40.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "df_base40 = get_baseline(0.4)\n",
    "earliness_means['int40'] = df_base40.mean()['earliness_mean']\n",
    "earliness_stds['int40'] = df_base40.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24318dc",
   "metadata": {},
   "source": [
    "## Baseline on 50% (internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "13fa0183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1162371449.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_means['int50'] = df_base50.mean()['earliness_mean']\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/1162371449.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  earliness_stds['int50'] = df_base50.std()['earliness_mean']\n"
     ]
    }
   ],
   "source": [
    "df_base50 = get_baseline(0.5)\n",
    "earliness_means['int50'] = df_base50.mean()['earliness_mean']\n",
    "earliness_stds['int50'] = df_base50.std()['earliness_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a94c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5e16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a886c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fbaebfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61e6f582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pairwise</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.200</td>\n",
       "      <td>0.266927</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pairwise</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.665</td>\n",
       "      <td>1.215730</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pairwise</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.732736</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.120</td>\n",
       "      <td>1.037184</td>\n",
       "      <td>0.296823</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pairwise</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.683240</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.065</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.250691</td>\n",
       "      <td>0.008047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pairwise</td>\n",
       "      <td>4</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.620</td>\n",
       "      <td>1.381055</td>\n",
       "      <td>0.275125</td>\n",
       "      <td>0.008972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>int40</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.813339</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.995</td>\n",
       "      <td>0.306390</td>\n",
       "      <td>0.358798</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>int50</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.565</td>\n",
       "      <td>0.407584</td>\n",
       "      <td>0.545334</td>\n",
       "      <td>0.023250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>int50</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.793521</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.520</td>\n",
       "      <td>0.683374</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.009799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>int50</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.827356</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.810</td>\n",
       "      <td>0.405663</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>0.006312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>int50</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.240</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.361766</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  level_1         model_x train_dataset eval_dataset  auc_mean  \\\n",
       "0   pairwise        0  AttentionModel          aumc         aumc  0.916687   \n",
       "1   pairwise        1  AttentionModel          aumc         eicu  0.698914   \n",
       "2   pairwise        2  AttentionModel          aumc        hirid  0.732736   \n",
       "3   pairwise        3  AttentionModel          aumc        mimic  0.683240   \n",
       "4   pairwise        4  AttentionModel          eicu         aumc  0.732401   \n",
       "..       ...      ...             ...           ...          ...       ...   \n",
       "63     int40        3  AttentionModel         mimic        mimic  0.813339   \n",
       "64     int50        0  AttentionModel          aumc         aumc  0.909833   \n",
       "65     int50        1  AttentionModel          eicu         eicu  0.793521   \n",
       "66     int50        2  AttentionModel         hirid        hirid  0.827356   \n",
       "67     int50        3  AttentionModel         mimic        mimic  0.815000   \n",
       "\n",
       "     auc_std  finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "0   0.003649      False     False              NaN   False  attn     \n",
       "1   0.010913      False     False              NaN   False  attn     \n",
       "2   0.013468      False     False              NaN   False  attn     \n",
       "3   0.013410      False     False              NaN   False  attn     \n",
       "4   0.006840      False     False              NaN   False  attn     \n",
       "..       ...        ...       ...              ...     ...     ...   \n",
       "63  0.001457      False      True              0.4   False  attn     \n",
       "64  0.004767      False      True              0.5   False  attn     \n",
       "65  0.003445      False      True              0.5   False  attn     \n",
       "66  0.001454      False      True              0.5   False  attn     \n",
       "67  0.001442      False      True              0.5   False  attn     \n",
       "\n",
       "    earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "0            4.200       0.266927        0.556745       0.022750  \n",
       "1            3.665       1.215730        0.270020       0.008207  \n",
       "2            3.120       1.037184        0.296823       0.012759  \n",
       "3            4.065       1.208770        0.250691       0.008047  \n",
       "4            3.620       1.381055        0.275125       0.008972  \n",
       "..             ...            ...             ...            ...  \n",
       "63           3.995       0.306390        0.358798       0.005626  \n",
       "64           3.565       0.407584        0.545334       0.023250  \n",
       "65           3.520       0.683374        0.348174       0.009799  \n",
       "66           2.810       0.405663        0.377411       0.006312  \n",
       "67           4.240       0.041833        0.361766       0.004234  \n",
       "\n",
       "[68 rows x 16 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1a1ecf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'level_0': 'task'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d0d19529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>level_1</th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ft10</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.784582</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.090</td>\n",
       "      <td>0.318983</td>\n",
       "      <td>0.318878</td>\n",
       "      <td>0.004958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ft10</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.835</td>\n",
       "      <td>0.815015</td>\n",
       "      <td>0.476981</td>\n",
       "      <td>0.039907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ft10</td>\n",
       "      <td>4</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.773977</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.740</td>\n",
       "      <td>0.668160</td>\n",
       "      <td>0.319227</td>\n",
       "      <td>0.002441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ft10</td>\n",
       "      <td>5</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.788518</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.490</td>\n",
       "      <td>0.171026</td>\n",
       "      <td>0.330190</td>\n",
       "      <td>0.007292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ft10</td>\n",
       "      <td>6</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.866544</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.130</td>\n",
       "      <td>1.262735</td>\n",
       "      <td>0.435645</td>\n",
       "      <td>0.033262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pairwise</td>\n",
       "      <td>10</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.833421</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.730</td>\n",
       "      <td>0.220369</td>\n",
       "      <td>0.392262</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pooled</td>\n",
       "      <td>0</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.836354</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.967180</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.027916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pooled</td>\n",
       "      <td>1</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.759689</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.390</td>\n",
       "      <td>1.001499</td>\n",
       "      <td>0.310632</td>\n",
       "      <td>0.010381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pooled</td>\n",
       "      <td>2</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.728090</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1.106882</td>\n",
       "      <td>0.289927</td>\n",
       "      <td>0.011515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pooled</td>\n",
       "      <td>3</td>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>pooled</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.719022</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.290</td>\n",
       "      <td>0.455041</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        task  level_1         model_x train_dataset eval_dataset  auc_mean  \\\n",
       "22      ft10        2  AttentionModel          aumc        mimic  0.784582   \n",
       "23      ft10        3  AttentionModel          eicu         aumc  0.873557   \n",
       "24      ft10        4  AttentionModel          eicu        hirid  0.773977   \n",
       "25      ft10        5  AttentionModel          eicu        mimic  0.788518   \n",
       "26      ft10        6  AttentionModel         hirid         aumc  0.866544   \n",
       "..       ...      ...             ...           ...          ...       ...   \n",
       "10  pairwise       10  AttentionModel         hirid        hirid  0.833421   \n",
       "16    pooled        0  AttentionModel        pooled         aumc  0.836354   \n",
       "17    pooled        1  AttentionModel        pooled         eicu  0.759689   \n",
       "18    pooled        2  AttentionModel        pooled        hirid  0.728090   \n",
       "19    pooled        3  AttentionModel        pooled        mimic  0.719022   \n",
       "\n",
       "     auc_std  finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "22  0.001923       True     False              0.1   False  attn     \n",
       "23  0.016987       True     False              0.1   False  attn     \n",
       "24  0.001597       True     False              0.1   False  attn     \n",
       "25  0.002695       True     False              0.1   False  attn     \n",
       "26  0.010388       True     False              0.1   False  attn     \n",
       "..       ...        ...       ...              ...     ...     ...   \n",
       "10  0.002325      False     False              NaN   False  attn     \n",
       "16  0.010690      False     False              NaN    True  attn     \n",
       "17  0.006701      False     False              NaN    True  attn     \n",
       "18  0.013592      False     False              NaN    True  attn     \n",
       "19  0.005418      False     False              NaN    True  attn     \n",
       "\n",
       "    earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "22           4.090       0.318983        0.318878       0.004958  \n",
       "23           2.835       0.815015        0.476981       0.039907  \n",
       "24           2.740       0.668160        0.319227       0.002441  \n",
       "25           3.490       0.171026        0.330190       0.007292  \n",
       "26           3.130       1.262735        0.435645       0.033262  \n",
       "..             ...            ...             ...            ...  \n",
       "10           2.730       0.220369        0.392262       0.007573  \n",
       "16           0.980       0.967180        0.397105       0.027916  \n",
       "17           1.390       1.001499        0.310632       0.010381  \n",
       "18           1.165       1.106882        0.289927       0.011515  \n",
       "19           3.290       0.455041        0.274747       0.006186  \n",
       "\n",
       "[68 rows x 16 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6f83d3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='task', ylabel='auc_mean'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.pointplot(x='task', y='auc_mean', data=df.sort_values(by=['task']), join=False, capsize=0.2)\n",
    "# wrong labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f50819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': 3.70375,\n",
       " 'pw': 3.0066666666666664,\n",
       " 'po': 1.7537500000000001,\n",
       " 'ft10': 3.116666666666667,\n",
       " 'int10': 6.03875,\n",
       " 'ft2': 3.507916666666667,\n",
       " 'int2': 6.921249999999999}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7dba7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measure(df, func, measure):\n",
    "    return getattr(df, func)()[measure]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "923de1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8500049019466496"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_measure(df_int, 'std', 'earliness_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b54c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['pw', 'po', 'ft2', 'int2', 'ft10', 'int10', 'int20', 'int30', 'int40', 'int50', 'int']\n",
    "df_ = [df_pw, df_po, df_ft2, df_base2, df_ft10, df_base10, df_base20, df_base30, df_base40, df_base50, df_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ec1231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df__ = pd.concat(df_) # for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e2a52b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model_x</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>eval_dataset</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>baseline</th>\n",
       "      <th>finetuning_size</th>\n",
       "      <th>pooled</th>\n",
       "      <th>model_y</th>\n",
       "      <th>earliness_mean</th>\n",
       "      <th>earliness_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">pairwise</th>\n",
       "      <th>1</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.665</td>\n",
       "      <td>1.215730</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.732736</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.120</td>\n",
       "      <td>1.037184</td>\n",
       "      <td>0.296823</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.683240</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.065</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.250691</td>\n",
       "      <td>0.008047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.620</td>\n",
       "      <td>1.381055</td>\n",
       "      <td>0.275125</td>\n",
       "      <td>0.008972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.704782</td>\n",
       "      <td>0.026302</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.595</td>\n",
       "      <td>1.117111</td>\n",
       "      <td>0.275680</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int50</th>\n",
       "      <th>3</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.240</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.361766</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pairwise</th>\n",
       "      <th>0</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>aumc</td>\n",
       "      <td>aumc</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.200</td>\n",
       "      <td>0.266927</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>eicu</td>\n",
       "      <td>eicu</td>\n",
       "      <td>0.802011</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>4.615</td>\n",
       "      <td>0.986724</td>\n",
       "      <td>0.347525</td>\n",
       "      <td>0.010727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>hirid</td>\n",
       "      <td>hirid</td>\n",
       "      <td>0.833421</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>2.730</td>\n",
       "      <td>0.220369</td>\n",
       "      <td>0.392262</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionModel</td>\n",
       "      <td>mimic</td>\n",
       "      <td>mimic</td>\n",
       "      <td>0.830490</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>attn</td>\n",
       "      <td>3.325</td>\n",
       "      <td>0.340955</td>\n",
       "      <td>0.381639</td>\n",
       "      <td>0.007537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_x train_dataset eval_dataset  auc_mean   auc_std  \\\n",
       "pairwise 1   AttentionModel          aumc         eicu  0.698914  0.010913   \n",
       "         2   AttentionModel          aumc        hirid  0.732736  0.013468   \n",
       "         3   AttentionModel          aumc        mimic  0.683240  0.013410   \n",
       "         4   AttentionModel          eicu         aumc  0.732401  0.006840   \n",
       "         6   AttentionModel          eicu        hirid  0.704782  0.026302   \n",
       "...                     ...           ...          ...       ...       ...   \n",
       "int50    3   AttentionModel         mimic        mimic  0.815000  0.001442   \n",
       "pairwise 0   AttentionModel          aumc         aumc  0.916687  0.003649   \n",
       "         5   AttentionModel          eicu         eicu  0.802011  0.003560   \n",
       "         10  AttentionModel         hirid        hirid  0.833421  0.002325   \n",
       "         15  AttentionModel         mimic        mimic  0.830490  0.003029   \n",
       "\n",
       "             finetuned  baseline  finetuning_size  pooled model_y  \\\n",
       "pairwise 1       False     False              NaN   False  attn     \n",
       "         2       False     False              NaN   False  attn     \n",
       "         3       False     False              NaN   False  attn     \n",
       "         4       False     False              NaN   False  attn     \n",
       "         6       False     False              NaN   False  attn     \n",
       "...                ...       ...              ...     ...     ...   \n",
       "int50    3       False      True              0.5   False  attn     \n",
       "pairwise 0       False     False              NaN   False  attn     \n",
       "         5       False     False              NaN   False  attn     \n",
       "         10      False     False              NaN   False  attn     \n",
       "         15      False     False              NaN   False  attn     \n",
       "\n",
       "             earliness_mean  earliness_std  precision_mean  precision_std  \n",
       "pairwise 1            3.665       1.215730        0.270020       0.008207  \n",
       "         2            3.120       1.037184        0.296823       0.012759  \n",
       "         3            4.065       1.208770        0.250691       0.008047  \n",
       "         4            3.620       1.381055        0.275125       0.008972  \n",
       "         6            2.595       1.117111        0.275680       0.019701  \n",
       "...                     ...            ...             ...            ...  \n",
       "int50    3            4.240       0.041833        0.361766       0.004234  \n",
       "pairwise 0            4.200       0.266927        0.556745       0.022750  \n",
       "         5            4.615       0.986724        0.347525       0.010727  \n",
       "         10           2.730       0.220369        0.392262       0.007573  \n",
       "         15           3.325       0.340955        0.381639       0.007537  \n",
       "\n",
       "[68 rows x 14 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9aca752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df__.to_csv('performance_finetuning_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e192ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    }
   ],
   "source": [
    "earliness_means = {}\n",
    "earliness_stds = {}\n",
    "for key, _df in zip(keys, df_):\n",
    "    earliness_means[key] = get_measure(_df, 'mean', 'earliness_mean')\n",
    "    earliness_stds[key] = get_measure(_df, 'std', 'earliness_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "74974e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pw': 3.0004166666666663,\n",
       " 'po': 1.70625,\n",
       " 'ft2': 3.507916666666667,\n",
       " 'int2': 6.921249999999999,\n",
       " 'ft10': 3.10875,\n",
       " 'int10': 6.0562499999999995,\n",
       " 'int20': 4.8325000000000005,\n",
       " 'int30': 4.455,\n",
       " 'int40': 4.015000000000001,\n",
       " 'int50': 3.5337500000000004,\n",
       " 'int': 3.7175000000000002}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliness_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95b4ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    }
   ],
   "source": [
    "precision_means = {}\n",
    "precision_stds = {}\n",
    "for key, _df in zip(keys, df_):\n",
    "    precision_means[key] = get_measure(_df, 'mean', 'precision_mean')\n",
    "    precision_stds[key] = get_measure(_df, 'std', 'precision_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0959b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_33595/3095324987.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return getattr(df, func)()[measure]\n"
     ]
    }
   ],
   "source": [
    "auc_means = {}\n",
    "auc_stds = {}\n",
    "for key, _df in zip(keys, df_):\n",
    "    auc_means[key] = get_measure(_df, 'mean', 'auc_mean')\n",
    "    auc_stds[key] = get_measure(_df, 'std', 'auc_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c6dd9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys_sorted = ['pw', 'po', 'ft2', 'ft10', 'ft10po', 'int']\n",
    "# keys_sorted = ['pw', 'po', 'ft2', 'int2', 'ft10', 'ft10po', 'int10', 'int']\n",
    "#keys_sorted = ['pw', 'po', 'ft2', 'ft10', 'int']\n",
    "keys_sorted = keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05c0d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_m = [auc_means[k] for k in keys_sorted]\n",
    "aucs_s = [auc_stds[k] for k in keys_sorted]\n",
    "earliness_m = [earliness_means[k] for k in keys_sorted]\n",
    "earliness_s = [earliness_stds[k] for k in keys_sorted]\n",
    "precision_m = [precision_means[k] for k in keys_sorted]\n",
    "precision_s = [precision_stds[k] for k in keys_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a5f0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pw': 0.7222374432087998,\n",
       " 'po': 0.760788842117371,\n",
       " 'ft2': 0.7632434823574797,\n",
       " 'int2': 0.7569484196682785,\n",
       " 'ft10': 0.8061305943971764,\n",
       " 'int10': 0.7812168159448447,\n",
       " 'int20': 0.8127737398041033,\n",
       " 'int30': 0.8259323201068559,\n",
       " 'int40': 0.8325654822469596,\n",
       " 'int50': 0.8364276384279943,\n",
       " 'int': 0.8456521348729381}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51f49fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pw': 0.04594252208119628,\n",
       " 'po': 0.05330698130539764,\n",
       " 'ft2': 0.04601003963594773,\n",
       " 'int2': 0.04005908386065097,\n",
       " 'ft10': 0.04553976039560453,\n",
       " 'int10': 0.04084609975134334,\n",
       " 'int20': 0.04594958738921339,\n",
       " 'int30': 0.05327639336692307,\n",
       " 'int40': 0.05017897009662403,\n",
       " 'int50': 0.05089479592793172,\n",
       " 'int': 0.04943025110753608}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad691f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d92f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_7769/3380255286.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_int['task'] = 'internal'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_7769/3380255286.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pw['task'] = 'pair-wise'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_7769/3380255286.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_po['task'] = 'pooled'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_7769/3380255286.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ft10['task'] = 'ft-10%'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_7769/3380255286.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ft2['task'] = 'ft-2%'\n",
      "/var/folders/vp/67rz7yg93fn4hrmg1q9wpbbm0000gn/T/ipykernel_7769/3380255286.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ft10po['task'] = 'ft-10%-pooled'\n"
     ]
    }
   ],
   "source": [
    "#df_int['task'] = 'internal'\n",
    "#df_pw['task'] = 'pair-wise' \n",
    "#df_po['task'] = 'pooled'\n",
    "#df_ft10['task'] = 'ft-10%' \n",
    "#df_ft2['task'] = 'ft-2%'\n",
    "#df_ft10po['task'] = 'ft-10%-pooled' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c13c74fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw values:\n",
    "df_tot = pd.concat([df_pw, df_po, df_ft2, df_ft10, df_ft10po, df_int])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb989ec",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- csv of these results\n",
    "- plot with increasingly smaller finetuning split\n",
    "- check nemati paper again\n",
    "- how much data collection can be prevented using pretraining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c6fda",
   "metadata": {},
   "source": [
    "# TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bafaa90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7222374432087998,\n",
       " 0.760788842117371,\n",
       " 0.7632434823574797,\n",
       " 0.7569484196682785,\n",
       " 0.8061305943971764,\n",
       " 0.7812168159448447,\n",
       " 0.8127737398041033,\n",
       " 0.8259323201068559,\n",
       " 0.8325654822469596,\n",
       " 0.8364276384279943,\n",
       " 0.8456521348729381]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5131962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pw',\n",
       " 'po',\n",
       " 'ft2',\n",
       " 'int2',\n",
       " 'ft10',\n",
       " 'int10',\n",
       " 'int20',\n",
       " 'int30',\n",
       " 'int40',\n",
       " 'int50',\n",
       " 'int']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbe8582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(10,12))\n",
    "plt.figure(figsize=(6,10))\n",
    "ax1 = plt.subplot(311)\n",
    "n_steps = 11 # 8\n",
    "x_pos = np.arange(n_steps) #7\n",
    "#aucs = [auc_pw_mean, auc_po_mean, auc_ft2_mean, auc_base2_mean, auc_ft10_mean, auc_base10_mean, auc_int_mean]\n",
    "#stds = [auc_pw_std, auc_po_std, auc_ft2_std, auc_base2_std, auc_ft10_std, auc_base10_std, auc_int_std]\n",
    "#names = ['pair-wise', 'pooled', 'ft-2%', 'int-2%', 'ft-10%', 'ft-10%-pooled', 'int-10%', 'internal']\n",
    "#names = ['pair-wise', 'pooled', 'ft-2%', 'ft-10%', 'internal']\n",
    "names = keys\n",
    "ax1.errorbar(x_pos, aucs_m, yerr=aucs_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "###sns.stripplot(x=\"task\", y=\"auc_mean\", data=df_tot2, jitter=0.1, ax=ax1,alpha=0.5)\n",
    "\n",
    "ax1.set_ylim(0.60,0.93)\n",
    "\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(names)\n",
    "#ax[0].tight_layout()\n",
    "ax1.set_ylabel(f'AUC')\n",
    "\n",
    "ax2 = plt.subplot(312, sharex= ax1)\n",
    "\n",
    "#plt.plot((2,3), (auc_ft2_mean, auc_base2_mean), '--', color='black')\n",
    "#plt.plot((4,5), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "#plt.hlines(auc_int_mean, 0,6, color='black', linestyle='dotted')\n",
    "###sns.stripplot(x=\"task\", y=\"precision_mean\", data=df_tot2, jitter=0.1, ax=ax2, alpha=0.5)\n",
    "ax2.errorbar(x_pos, precision_m, yerr=precision_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "ax2.set_ylabel(f'PPV @ 80% Sensitivity')\n",
    "ax2.set_ylim(0.15,0.55)\n",
    "\n",
    "#ax[1].set_xticklabels(names)\n",
    "#ax[1].tight_layout()\n",
    "\n",
    "ax3 = plt.subplot(313, sharex= ax1)\n",
    "###sns.stripplot(x=\"task\", y=\"earliness_mean\", data=df_tot2, jitter=0.1, ax=ax3, alpha=0.5)\n",
    "ax3.errorbar(x_pos, earliness_m, yerr=earliness_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "ax3.set_ylabel(f'Earliness @ 80% Sensitivity')\n",
    "#ax[2].set_xticklabels(names)\n",
    "ax3.set_ylim(-0.2,9.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "x1 = np.arange(n_steps)\n",
    "y1 = np.array([0.13] * n_steps)\n",
    "for i,j, n in zip(x1,y1, aucs_m):\n",
    "    ax1.annotate(f'{n:.2f}',xy=(i-0.1,j+0.5), size=12)\n",
    "y2 = np.array([0.18] * n_steps)\n",
    "\n",
    "for i,j, n in zip(x1,y2, precision_m):\n",
    "    ax2.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)\n",
    "\n",
    "y3 = np.array([0.2] * n_steps)\n",
    "for i,j, n in zip(x1,y3, earliness_m):\n",
    "    ax3.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "da556578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(10,12))\n",
    "plt.figure(figsize=(5,6))\n",
    "ax1 = plt.subplot(111)\n",
    "n_steps = 5 # 8\n",
    "x_pos = np.arange(n_steps) #7\n",
    "#aucs = [auc_pw_mean, auc_po_mean, auc_ft2_mean, auc_base2_mean, auc_ft10_mean, auc_base10_mean, auc_int_mean]\n",
    "#stds = [auc_pw_std, auc_po_std, auc_ft2_std, auc_base2_std, auc_ft10_std, auc_base10_std, auc_int_std]\n",
    "#names = ['pair-wise', 'pooled', 'ft-2%', 'int-2%', 'ft-10%', 'ft-10%-pooled', 'int-10%', 'internal']\n",
    "names = ['pair-wise', 'pooled', 'ft-2%', 'ft-10%', 'internal']\n",
    "ax1.errorbar(x_pos, aucs_m, yerr=aucs_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "sns.stripplot(x=\"task\", y=\"auc_mean\", data=df_tot2, jitter=0.1, ax=ax1,alpha=0.5)\n",
    "\n",
    "ax1.set_ylim(0.6,0.93)\n",
    "\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(names)\n",
    "#ax[0].tight_layout()\n",
    "ax1.set_ylabel(f'AUC')\n",
    "\n",
    "# ax2 = plt.subplot(312, sharex= ax1)\n",
    "\n",
    "# #plt.plot((2,3), (auc_ft2_mean, auc_base2_mean), '--', color='black')\n",
    "# #plt.plot((4,5), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "# #plt.hlines(auc_int_mean, 0,6, color='black', linestyle='dotted')\n",
    "# sns.stripplot(x=\"task\", y=\"precision_mean\", data=df_tot2, jitter=0.1, ax=ax2, alpha=0.5)\n",
    "# ax2.errorbar(x_pos, precision_m, yerr=precision_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "# ax2.set_ylabel(f'PPV @ 80% Sensitivity')\n",
    "# ax2.set_ylim(0.15,0.55)\n",
    "\n",
    "# #ax[1].set_xticklabels(names)\n",
    "# #ax[1].tight_layout()\n",
    "\n",
    "# ax3 = plt.subplot(313, sharex= ax1)\n",
    "# sns.stripplot(x=\"task\", y=\"earliness_mean\", data=df_tot2, jitter=0.1, ax=ax3, alpha=0.5)\n",
    "# ax3.errorbar(x_pos, earliness_m, yerr=earliness_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "# ax3.set_ylabel(f'Earliness @ 80% Sensitivity')\n",
    "# #ax[2].set_xticklabels(names)\n",
    "# ax3.set_ylim(-0.2,6.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "x1 = np.arange(n_steps)\n",
    "y1 = np.array([0.13] * n_steps)\n",
    "for i,j, n in zip(x1,y1, aucs_m):\n",
    "    ax1.annotate(r'{:.2f}'.format(n),xy=(i-0.1,j+0.5), size=12, weight='bold')\n",
    "# y2 = np.array([0.18] * n_steps)\n",
    "\n",
    "# for i,j, n in zip(x1,y2, precision_m):\n",
    "#     ax2.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)\n",
    "\n",
    "# y3 = np.array([0.2] * n_steps)\n",
    "# for i,j, n in zip(x1,y3, earliness_m):\n",
    "#     ax3.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc3fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f46e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_sorted = ['ft10', 'int10', 'int']\n",
    "aucs_m = [auc_means[k] for k in keys_sorted]\n",
    "aucs_s = [auc_stds[k] for k in keys_sorted]\n",
    "earliness_m = [earliness_means[k] for k in keys_sorted]\n",
    "earliness_s = [earliness_stds[k] for k in keys_sorted]\n",
    "precision_m = [precision_means[k] for k in keys_sorted]\n",
    "precision_s = [precision_stds[k] for k in keys_sorted]\n",
    "\n",
    "df_tot3 = pd.concat([df_ft10, df_base10, df_int])\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "ax1 = plt.subplot(311)\n",
    "n_steps = 3\n",
    "x_pos = np.arange(n_steps) #7\n",
    "#aucs = [auc_pw_mean, auc_po_mean, auc_ft2_mean, auc_base2_mean, auc_ft10_mean, auc_base10_mean, auc_int_mean]\n",
    "#stds = [auc_pw_std, auc_po_std, auc_ft2_std, auc_base2_std, auc_ft10_std, auc_base10_std, auc_int_std]\n",
    "names = ['ft-10%', 'int-10%', 'internal-100%']\n",
    "ax1.errorbar(x_pos, aucs_m, yerr=aucs_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "sns.stripplot(x=\"task\", y=\"auc_mean\", data=df_tot3, jitter=0.1, ax=ax1,alpha=0.5)\n",
    "\n",
    "ax1.set_ylim(0.70,0.93)\n",
    "\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(names)\n",
    "#ax[0].tight_layout()\n",
    "ax1.set_ylabel(f'AUROC')\n",
    "\n",
    "# ax2 = plt.subplot(312, sharex= ax1)\n",
    "\n",
    "# #plt.plot((2,3), (auc_ft2_mean, auc_base2_mean), '--', color='black')\n",
    "# #plt.plot((4,5), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "# #plt.hlines(auc_int_mean, 0,6, color='black', linestyle='dotted')\n",
    "# sns.stripplot(x=\"task\", y=\"precision_mean\", data=df_tot2, jitter=0.1, ax=ax2, alpha=0.5)\n",
    "# ax2.errorbar(x_pos, precision_m, yerr=precision_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "# ax2.set_ylabel(f'PPV @ 80% Sensitivity')\n",
    "# ax2.set_ylim(0.15,0.55)\n",
    "\n",
    "# #ax[1].set_xticklabels(names)\n",
    "# #ax[1].tight_layout()\n",
    "\n",
    "# ax3 = plt.subplot(313, sharex= ax1)\n",
    "# sns.stripplot(x=\"task\", y=\"earliness_mean\", data=df_tot2, jitter=0.1, ax=ax3, alpha=0.5)\n",
    "# ax3.errorbar(x_pos, earliness_m, yerr=earliness_s, ecolor='black', capsize=10, fmt='d', color='black')\n",
    "# ax3.set_ylabel(f'Earliness @ 80% Sensitivity')\n",
    "# #ax[2].set_xticklabels(names)\n",
    "# ax3.set_ylim(-0.2,6.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "x1 = np.arange(n_steps)\n",
    "y1 = np.array([0.13] * n_steps)\n",
    "for i,j, n in zip(x1,y1, aucs_m):\n",
    "    ax1.annotate(f'{n:.2f}',xy=(i-0.1,j+0.58), size=12)\n",
    "y2 = np.array([0.18] * n_steps)\n",
    "\n",
    "# for i,j, n in zip(x1,y2, precision_m):\n",
    "#     ax2.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)\n",
    "\n",
    "# y3 = np.array([0.2] * n_steps)\n",
    "# for i,j, n in zip(x1,y3, earliness_m):\n",
    "#     ax3.annotate(f'{n:.2f}',xy=(i-0.1,j), size=12)\n",
    "    \n",
    "plt.plot((0,1), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "#plt.plot((4,5), (auc_ft10_mean, auc_base10_mean), '--', color='black')\n",
    "#plt.hlines(auc_int_mean, 0,2, color='black', linestyle='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdde590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
